{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import json\n",
    "# import pyodbc\n",
    "import string\n",
    "import datetime\n",
    "from datetime import date\n",
    "import pickle\n",
    "import random\n",
    "import helper\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to database\n",
      "host='localhost' dbname='lit_review' user='postgres' password='gres'\n"
     ]
    }
   ],
   "source": [
    "#Define our connection string\n",
    "conn_string = \"host='localhost' dbname='lit_review' user='postgres' password='gres'\"\n",
    " \n",
    "# print the connection string we will use to connect\n",
    "print(\"Connecting to database\\n\" + conn_string)\n",
    " \n",
    "# get a connection, if a connect cannot be made an exception will be raised here\n",
    "conn = psycopg2.connect(conn_string)\n",
    " \n",
    "# conn.cursor will return a cursor object, you can use this cursor to perform queries\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT * FROM information_schema.tables \")\n",
    "\n",
    "# cursor.execute(\"SHOW search_path\")\n",
    "# cursor.execute(\"SELECT * FROM information_schema.columns\")\n",
    "# cursor.execute(\"SET search_path TO public\")\n",
    "#                where table_name = public.DataPull_Detail'\")\n",
    "# cursor.fetchall()\n",
    "\n",
    "# # cursor = conn.cursor('cursor_unique_name', cursor_factory=psycopg2.extras.DictCursor)\n",
    "# cursor.execute('SELECT * FROM public.DataPull_Detail LIMIT 1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " '04/12/2018 03:09:59 PM',\n",
       " 'test',\n",
       " 'public health',\n",
       " 'keyword',\n",
       " 'PMC',\n",
       " 'Sophie')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'04/12/2018 03:22:23 PM'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_string = \"host='localhost' dbname='lit_review' user='postgres' password='gres'\"\n",
    "conn = psycopg2.connect(conn_string)\n",
    " \n",
    "# conn.cursor will return a cursor object, you can use this cursor to perform queries\n",
    "cursor = conn.cursor()\n",
    "\n",
    "pull_id = 1\n",
    "pull_date = datetime.datetime.now().strftime('%m/%d/%Y %I:%M:%S %p')\n",
    "pull_name = 'test'\n",
    "pull_query = 'public health'\n",
    "pull_type = 'keyword' #keyword/ author\n",
    "pull_source = 'pmc'.upper()\n",
    "pull_by = 'Sophie'\n",
    "\n",
    "# cursor.execute(\"insert into DataPull_ID (PullID,PullDate,PullName,PullQuery,PullType,PullSource,PullBy) VALUES(%s,%s,%s,%s,%s,%s,%s)\",(pull_id,pull_date,pull_name,pull_query,pull_type,pull_source,pull_by))\n",
    "\n",
    "# cursor.execute(\"SELECT * FROM information_schema.columns\").fetchall()\n",
    "# args = (pull_id,pull_date,pull_name,pull_query,pull_type,pull_source,pull_by)\n",
    "\n",
    "# cursor.execute(query, args)\n",
    "#must commit in order to see it on sql server, if not sql server database won't load correctly\n",
    "# conn.commit()\n",
    "# cursor.close()\n",
    "# conn.close()\n",
    "pull_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = [ 'DataPull_ID','DataPull_Detail','DataPull_Journal','DataPull_Author','DataPull_Text','DataPull_Title','DataPull_Keyword']\n",
    "table_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>associatedId</th>\n",
       "      <th>author</th>\n",
       "      <th>journalISO</th>\n",
       "      <th>journalName</th>\n",
       "      <th>meshterms</th>\n",
       "      <th>optionalId01</th>\n",
       "      <th>optionalId02</th>\n",
       "      <th>publishdate</th>\n",
       "      <th>publishdatefull</th>\n",
       "      <th>pubtype</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'label': 'OBJECTIVES', 'nlmcategory': 'OBJEC...</td>\n",
       "      <td>29153972</td>\n",
       "      <td>[{'fname': 'E K', 'lname': 'Tsui', 'affl': 'De...</td>\n",
       "      <td>Public Health</td>\n",
       "      <td>Public health</td>\n",
       "      <td>[{'descriptorname': 'Humans'}, {'descriptornam...</td>\n",
       "      <td>10.1016/j.puhe.2017.10.008</td>\n",
       "      <td>None</td>\n",
       "      <td>{'year': '2017', 'month': '11', 'day': '21'}</td>\n",
       "      <td>11/21/2017</td>\n",
       "      <td>[Journal Article, Review]</td>\n",
       "      <td>Uses of oral history and digital storytelling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'text': 'The Canadian government decision to...</td>\n",
       "      <td>28759883</td>\n",
       "      <td>[{'fname': 'R T', 'lname': 'Wilson', 'affl': '...</td>\n",
       "      <td>Public Health</td>\n",
       "      <td>Public health</td>\n",
       "      <td>[{'descriptorname': 'Censuses'}, {'descriptorn...</td>\n",
       "      <td>10.1016/j.puhe.2017.05.015</td>\n",
       "      <td>None</td>\n",
       "      <td>{'year': '2017', 'month': '8', 'day': '2'}</td>\n",
       "      <td>8/2/2017</td>\n",
       "      <td>[Journal Article, Review]</td>\n",
       "      <td>Challenges to the census: international trends...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'label': 'OBJECTIVES', 'nlmcategory': 'OBJEC...</td>\n",
       "      <td>27931992</td>\n",
       "      <td>[{'fname': 'X X', 'lname': 'Zhan', 'affl': 'De...</td>\n",
       "      <td>Public Health</td>\n",
       "      <td>Public health</td>\n",
       "      <td>[{'descriptorname': 'Adult'}, {'descriptorname...</td>\n",
       "      <td>10.1016/j.puhe.2016.09.007</td>\n",
       "      <td>None</td>\n",
       "      <td>{'year': '2016', 'month': '12', 'day': '10'}</td>\n",
       "      <td>12/10/2016</td>\n",
       "      <td>[Journal Article]</td>\n",
       "      <td>The attitudes of primary healthcare providers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'label': 'OBJECTIVES', 'nlmcategory': 'OBJEC...</td>\n",
       "      <td>26993202</td>\n",
       "      <td>[{'fname': 'L', 'lname': 'Rosella', 'affl': 'D...</td>\n",
       "      <td>Public Health</td>\n",
       "      <td>Public health</td>\n",
       "      <td>[{'descriptorname': 'Humans'}, {'descriptornam...</td>\n",
       "      <td>10.1016/j.puhe.2015.10.027</td>\n",
       "      <td>None</td>\n",
       "      <td>{'year': '2016', 'month': '3', 'day': '20'}</td>\n",
       "      <td>3/20/2016</td>\n",
       "      <td>[Journal Article]</td>\n",
       "      <td>The development and validation of a meta-tool ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'label': 'OBJECTIVES', 'nlmcategory': 'OBJEC...</td>\n",
       "      <td>27062067</td>\n",
       "      <td>[{'fname': 'P K', 'lname': 'Franklin', 'affl':...</td>\n",
       "      <td>Public Health</td>\n",
       "      <td>Public health</td>\n",
       "      <td>[{'descriptorname': 'European Union'}, {'descr...</td>\n",
       "      <td>10.1016/j.puhe.2016.02.034</td>\n",
       "      <td>None</td>\n",
       "      <td>{'year': '2016', 'month': '4', 'day': '11'}</td>\n",
       "      <td>4/11/2016</td>\n",
       "      <td>[Journal Article]</td>\n",
       "      <td>Public health within the EU policy space: a qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract associatedId  \\\n",
       "0  [{'label': 'OBJECTIVES', 'nlmcategory': 'OBJEC...     29153972   \n",
       "1  [{'text': 'The Canadian government decision to...     28759883   \n",
       "2  [{'label': 'OBJECTIVES', 'nlmcategory': 'OBJEC...     27931992   \n",
       "3  [{'label': 'OBJECTIVES', 'nlmcategory': 'OBJEC...     26993202   \n",
       "4  [{'label': 'OBJECTIVES', 'nlmcategory': 'OBJEC...     27062067   \n",
       "\n",
       "                                              author     journalISO  \\\n",
       "0  [{'fname': 'E K', 'lname': 'Tsui', 'affl': 'De...  Public Health   \n",
       "1  [{'fname': 'R T', 'lname': 'Wilson', 'affl': '...  Public Health   \n",
       "2  [{'fname': 'X X', 'lname': 'Zhan', 'affl': 'De...  Public Health   \n",
       "3  [{'fname': 'L', 'lname': 'Rosella', 'affl': 'D...  Public Health   \n",
       "4  [{'fname': 'P K', 'lname': 'Franklin', 'affl':...  Public Health   \n",
       "\n",
       "     journalName                                          meshterms  \\\n",
       "0  Public health  [{'descriptorname': 'Humans'}, {'descriptornam...   \n",
       "1  Public health  [{'descriptorname': 'Censuses'}, {'descriptorn...   \n",
       "2  Public health  [{'descriptorname': 'Adult'}, {'descriptorname...   \n",
       "3  Public health  [{'descriptorname': 'Humans'}, {'descriptornam...   \n",
       "4  Public health  [{'descriptorname': 'European Union'}, {'descr...   \n",
       "\n",
       "                 optionalId01 optionalId02  \\\n",
       "0  10.1016/j.puhe.2017.10.008         None   \n",
       "1  10.1016/j.puhe.2017.05.015         None   \n",
       "2  10.1016/j.puhe.2016.09.007         None   \n",
       "3  10.1016/j.puhe.2015.10.027         None   \n",
       "4  10.1016/j.puhe.2016.02.034         None   \n",
       "\n",
       "                                    publishdate publishdatefull  \\\n",
       "0  {'year': '2017', 'month': '11', 'day': '21'}      11/21/2017   \n",
       "1    {'year': '2017', 'month': '8', 'day': '2'}        8/2/2017   \n",
       "2  {'year': '2016', 'month': '12', 'day': '10'}      12/10/2016   \n",
       "3   {'year': '2016', 'month': '3', 'day': '20'}       3/20/2016   \n",
       "4   {'year': '2016', 'month': '4', 'day': '11'}       4/11/2016   \n",
       "\n",
       "                     pubtype  \\\n",
       "0  [Journal Article, Review]   \n",
       "1  [Journal Article, Review]   \n",
       "2          [Journal Article]   \n",
       "3          [Journal Article]   \n",
       "4          [Journal Article]   \n",
       "\n",
       "                                               title  \n",
       "0  Uses of oral history and digital storytelling ...  \n",
       "1  Challenges to the census: international trends...  \n",
       "2  The attitudes of primary healthcare providers ...  \n",
       "3  The development and validation of a meta-tool ...  \n",
       "4  Public health within the EU policy space: a qu...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_list_fetch = helper.id_run('parse')\n",
    "parse_list_fetch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define our connection string\n",
    "conn_string = \"host='localhost' dbname='lit_review' user='postgres' password='gres'\"\n",
    "cnxn = psycopg2.connect(conn_string)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#Functions to push data to database\n",
    "#Determining Pull Id\n",
    "def pull_Id(cnxn):\n",
    "    query = \"select max(PullID) from public.'DataPull_ID'\"\n",
    "    pull_Id_Df = pd.read_sql_query(query,cnxn)\n",
    "    pull_Id_Df.columns = ['maxPullId']\n",
    "    id_val = pull_Id_Df['maxPullId'].isnull()\n",
    "    if id_val.bool():\n",
    "        pull_val = 1\n",
    "    else:\n",
    "        pull_id_series = pull_Id_Df['maxPullId'] + 1\n",
    "        pull_val = pull_id_series.iloc[0]\n",
    "    return pull_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'select max(PullID) as a from public.'DataPull_ID'': syntax error at or near \"'DataPull_ID'\"\nLINE 1: select max(PullID) as a from public.'DataPull_ID'\n                                            ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1408\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: syntax error at or near \"'DataPull_ID'\"\nLINE 1: select max(PullID) as a from public.'DataPull_ID'\n                                            ^\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-cf806be4fb42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"select max(PullID) as a from public.'DataPull_ID'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpull_Id_Df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcnxn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m    330\u001b[0m     return pandas_sql.read_query(\n\u001b[1;32m    331\u001b[0m         \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         parse_dates=parse_dates, chunksize=chunksize)\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             ex = DatabaseError(\n\u001b[1;32m   1420\u001b[0m                 \"Execution failed on sql '%s': %s\" % (args[0], exc))\n\u001b[0;32m-> 1421\u001b[0;31m             \u001b[0mraise_with_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36mraise_with_traceback\u001b[0;34m(exc, traceback)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEllipsis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;31m# this version of raise is a syntax error in Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'select max(PullID) as a from public.'DataPull_ID'': syntax error at or near \"'DataPull_ID'\"\nLINE 1: select max(PullID) as a from public.'DataPull_ID'\n                                            ^\n"
     ]
    }
   ],
   "source": [
    "query = \"select max(PullID) as a from public.'DataPull_ID'\"\n",
    "pull_Id_Df = pd.read_sql_query(query,cnxn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to push data to database\n",
    "#Determining Pull Id\n",
    "def pull_Id(cnxn):\n",
    "    query = \"select max(PullID) from DataPull_ID\"\n",
    "    pull_Id_Df = pd.read_sql_query(query,cnxn)\n",
    "    pull_Id_Df.columns = ['maxPullId']\n",
    "    id_val = pull_Id_Df['maxPullId'].isnull()\n",
    "    if id_val.bool():\n",
    "        pull_val = 1\n",
    "    else:\n",
    "        pull_id_series = pull_Id_Df['maxPullId'] + 1\n",
    "        pull_val = pull_id_series.iloc[0]\n",
    "    return pull_val\n",
    "\n",
    "\n",
    "def DataPull_ID(cnxn,cur,pull_val,terms,db):\n",
    "    try:\n",
    "        pull_id = pull_val.item()\n",
    "    except:\n",
    "        pull_id = pull_val\n",
    "\n",
    "    pull_date = datetime.datetime.now().strftime('%m/%d/%Y %I:%M:%S %p')\n",
    "    pull_name = terms\n",
    "    pull_query = terms\n",
    "    pull_type = 'keyword' #keyword/ author\n",
    "    pull_source = db.upper()\n",
    "    pull_by = 'Sophie'\n",
    "\n",
    "    query = \"\"\" insert into DataPull_ID (PullID,PullDate,PullName,PullQuery,PullType,PullSource,PullBy) \n",
    "                values (?,?,?,?,?,?,?) \"\"\"\n",
    "\n",
    "    args = (pull_id,pull_date,pull_name,pull_query,pull_type,pull_source,pull_by)\n",
    "\n",
    "    cur.execute(query, args)\n",
    "    #must commit in order to see it on sql server, if not sql server database won't load correctly\n",
    "    cnxn.commit()\n",
    "\n",
    "def DataPull_Detail(cnxn,cur,parse_df,db):\n",
    "    #populate details table\n",
    "    # accessPK = cur.execute(\"select @@IDENTITY\").fetchall()[0][0].__str__()\n",
    "    accessPK = cur.execute(\"select Dmax('ID','DataPull_ID')\").fetchall()[0][0].__str__()\n",
    "    pullId = cur.execute(\"select distinct PullID from DataPull_ID where ID = ?\", (accessPK)).fetchall()[0][0].__str__()\n",
    "\n",
    "    aidList = cur.execute(\"\"\"select distinct b.AssociatedID from DataPull_ID as a inner join DataPull_Detail as b on a.PullID = b.PullID where a.PullSource = ?\"\"\",db).fetchall()\n",
    "    existing_ids = {associatedid[0] for associatedid in aidList}\n",
    "#     existing_ids\n",
    "\n",
    "    note = None\n",
    "\n",
    "    values_list = []\n",
    "\n",
    "    for index,row in parse_df.iterrows():\n",
    "\n",
    "        associatedidInt = int(row['associatedId'])\n",
    "        associatedid = str(associatedidInt)  \n",
    "        #check if associatedid is already in the database\n",
    "        if associatedid in existing_ids:\n",
    "            valuestore = 'duplicate'\n",
    "            #drop the row that already exists\n",
    "            parse_df.drop(index, inplace=True)\n",
    "        else:\n",
    "            valuestore = 'store'\n",
    "        for pt in row['pubtype']:\n",
    "            pub_type_val = pt\n",
    "            values_list.append((pullId,associatedid,valuestore,pt,note))\n",
    "\n",
    "    query = \"\"\" insert into DataPull_Detail ([PullID],[AssociatedID],[ValueStore],[PubType],[Note]) \n",
    "                                values (?,?,?,?,?) \"\"\"\n",
    "    if values_list!=[]:\n",
    "            cur.executemany(query, values_list)\n",
    "            cnxn.commit()\n",
    "\n",
    "def DataPull_Title(cnxn,cur,parse_df):\n",
    "    values_list = []\n",
    "\n",
    "    for index,row in parse_df.iterrows():\n",
    "        associatedid = int(row['associatedId'])\n",
    "        title = row['title']\n",
    "        journalName = row['journalName']\n",
    "        journalISO = row['journalISO']\n",
    "        pubdate = row['publishdatefull']\n",
    "        try:\n",
    "            pubDay = row['publishdate']['day']\n",
    "        except:\n",
    "            pubDay = None\n",
    "        try:\n",
    "            pubMonth = row['publishdate']['month']\n",
    "        except:\n",
    "            pubMonth = None\n",
    "        try:\n",
    "            pubYear = row['publishdate']['year']\n",
    "        except:\n",
    "            pubYear = Non\n",
    "        optionalId01 = row['optionalId01']\n",
    "        optionalId02 = row['optionalId02']    \n",
    "\n",
    "        values_list.append((associatedid, title, journalName, journalISO ,pubdate,pubDay,pubMonth,pubYear, optionalId01,optionalId02))\n",
    "\n",
    "    query = \"\"\" insert into DataPull_Title (AssociatedID, Title, JournalName,JournalISO, PublicationDate, pubDay,pubMonth,pubYear, OptionalID01,OptionalID02) values (?,?,?,?,?,?,?,?,?,?) \"\"\"\n",
    "\n",
    "    if values_list!=[]:\n",
    "        cur.executemany(query, values_list)\n",
    "        cnxn.commit()\n",
    "\n",
    "\n",
    "def DataPull_Keyword(cnxn,cur,parse_df):\n",
    "    values_list = []\n",
    "\n",
    "    for index,row in parse_df.iterrows():\n",
    "        associatedid = int(row['associatedId'])\n",
    "        if row['meshterms'] is not None:\n",
    "            for word in row['meshterms']:\n",
    "                keywordvalue = word['descriptorname']\n",
    "                try:\n",
    "                    num_of_qualifiers = len(word['qualifiername'])\n",
    "                except:\n",
    "                    num_of_qualifiers = 0\n",
    "\n",
    "                if num_of_qualifiers > 5:\n",
    "                    num_of_Nones = 0\n",
    "                    word['qualifiername'] = word['qualifiername'][:5]\n",
    "                else:\n",
    "                    num_of_Nones = 5 - num_of_qualifiers\n",
    "\n",
    "                #if there are qualifier names, the list should not be 0\n",
    "\n",
    "                if num_of_qualifiers != 0:\n",
    "                    values_list.append(([associatedid,keywordvalue] + word['qualifiername'] + [None]*num_of_Nones)) \n",
    "                else:\n",
    "                    values_list.append((associatedid, keywordvalue, None, None, None, None, None))\n",
    "\n",
    "    query = \"\"\" insert into DataPull_Keyword (AssociatedID, KeywordValue, Category1, Category2,\n",
    "                        Category3, Category4, Category5) values (?,?,?,?,?,?,?)\"\"\"\n",
    "    if values_list!=[]:\n",
    "        cur.executemany(query, values_list)\n",
    "        cnxn.commit()\n",
    "\n",
    "\n",
    "def DataPull_Authors(cnxn,cur,parse_df):\n",
    "    values_list = []\n",
    "\n",
    "    for index,row in parse_df.iterrows():\n",
    "        associatedid = int(row['associatedId'])\n",
    "        auth_count = 0\n",
    "\n",
    "        if row['author'] is not None:\n",
    "            for auth in row['author']:\n",
    "                auth_count += 1\n",
    "                if auth_count < 4:\n",
    "                    values_list.append((associatedid, auth['fname'], auth['lname'], auth['affl']))\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    query = \"\"\" insert into DataPull_Author (AssociatedID, ForeName, LastName, Affiliation) values (?,?,?,?) \"\"\"\n",
    "    if values_list!=[]:\n",
    "        cur.executemany(query, values_list)\n",
    "        cnxn.commit()\n",
    "\n",
    "\n",
    "def DataPull_Text(cnxn,cur,parse_df):\n",
    "    values_list = []\n",
    "\n",
    "    for index,row in parse_df.iterrows():\n",
    "        associatedid = int(row['associatedId'])\n",
    "        if row['abstract'] is not None:\n",
    "            for part in row['abstract']:\n",
    "                abstracttext = part['text']\n",
    "                try:\n",
    "                    label = part['label']\n",
    "                except:\n",
    "                    label = None\n",
    "                try:\n",
    "                    nlmcategory = part['nlmcategory']\n",
    "                except:\n",
    "                    nlmcategory = None\n",
    "                values_list.append((associatedid,nlmcategory,label,abstracttext))\n",
    "    query = \"\"\" insert into DataPull_Text (associatedid, nlmcategory, label, abstracttext) values (?,?,?,?)\"\"\"\n",
    "\n",
    "    if values_list!=[]:\n",
    "        cur.executemany(query, values_list)\n",
    "        cnxn.commit()\n",
    "\n",
    "\n",
    "#function to save the push id\n",
    "def to_json(unique_identifier_push):\n",
    "    json.dump(unique_identifier_push,open(\"unique_identifier_push.json\",\"w\"))\n",
    "\n",
    "\n",
    "#Import serialized parsed dataframe by it's unique identifier\n",
    "def import_parse_df(path_name):  \n",
    "    parse_df_path = path_name\n",
    "    with open(parse_df_path, 'rb') as f:\n",
    "        parse_df = pickle.load(f) \n",
    "    return parse_df\n",
    "\n",
    "\n",
    "def create_cnxn(db_name): \n",
    "    conn_str = 'DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=%s;' % db_name\n",
    "    cnxn = pyodbc.connect(conn_str)\n",
    "    cur = cnxn.cursor()\n",
    "    return cnxn,cur\n",
    "\n",
    "\n",
    "\n",
    "def main(parsed_path_name,term,db_name,db):\n",
    "    character_set = string.ascii_letters\n",
    "    character_set += string.digits\n",
    "    \n",
    "    unique_identifier_push = ''\n",
    "    \n",
    "    for _ in range(25):\n",
    "        unique_identifier_push += random.choice(character_set)\n",
    "      \n",
    "    #Retrieve parsed dataframe\n",
    "    parse_df = import_parse_df(parsed_path_name)\n",
    "    \n",
    "    #Create connection with database - db is the database we are pushing to\n",
    "    cnxn,cur = create_cnxn(db_name)\n",
    "    \n",
    "    #determine pull_id\n",
    "    pull_val = pull_Id(cnxn)\n",
    "    \n",
    "    #push to DataPull_ID table - db is the db pulled from (PMC or PUBMED)\n",
    "    DataPull_ID(cnxn,cur,pull_val,term,db)\n",
    "    \n",
    "    #push to DataPull_Detail table\n",
    "    DataPull_Detail(cnxn,cur,parse_df,db)\n",
    "    \n",
    "    #push to DataPull_Table table\n",
    "    DataPull_Title(cnxn,cur,parse_df)\n",
    "    \n",
    "    #push to DataPull_Keyword table\n",
    "    DataPull_Keyword(cnxn,cur,parse_df)\n",
    "    \n",
    "    #push to DataPull_Authors    \n",
    "    DataPull_Authors(cnxn,cur,parse_df)\n",
    "    \n",
    "    #push to DataPull_Text Table\n",
    "    DataPull_Text(cnxn,cur,parse_df)   \n",
    "    \n",
    "    return unique_identifier_push, int(pull_val), parse_df.shape[0]\n",
    "\n",
    "\n",
    "def ex_main_push(parsed_path_name,term,db_name,db):\n",
    "  unique_identifier_push_list = []\n",
    "  run_main = main(parsed_path_name,term,db_name,db)\n",
    "  unique_identifier_push_list.append(run_main[0])\n",
    "  unique_identifier_push_list.append(run_main[1])\n",
    "  unique_identifier_push_list.append(run_main[2])\n",
    "  to_json(unique_identifier_push_list)\n",
    "  \n",
    "\n",
    "#Run main and save unique_id and pull id to json\n",
    "if __name__ == '__main__':\n",
    "    unique_identifier_fetch = ex_main_push(parsed_path_name,term,db_name,db)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
