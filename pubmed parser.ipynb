{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import types\n",
    "import xml.etree.ElementTree as ET\n",
    "import lxml.html\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc =  open('myxmlfile.xml').read()\n",
    "xml = lxml.html.fromstring(doc)\n",
    "article = xml.xpath(\"//pubmedarticle\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title\n",
    "articleTitle = article.xpath('//articletitle')[0].text_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Journal title\n",
    "journalTags = [elem for elem in article.xpath('//journal/*')]\n",
    "journalList = []\n",
    "# [elem.tag for elem in article.xpath('//journal/*')]\n",
    "for j, jt in enumerate(journalTags):\n",
    "    journalDict = {}\n",
    "    journalDict[jt.tag] = jt.text_content()\n",
    "    journalList.append(journalDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth(node):\n",
    "    d = 0\n",
    "    while node is not None:\n",
    "        d += 1\n",
    "        node = node.getparent()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for node in tree.iter('page'):\n",
    "    print depth(node)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'journal': 'issn'},\n",
       " {'journal': 'journalissue'},\n",
       " {'journalissue': 'volume'},\n",
       " {'journalissue': 'issue'},\n",
       " {'journalissue': 'pubdate'},\n",
       " {'pubdate': 'year'},\n",
       " {'pubdate': 'month'},\n",
       " {'pubdate': 'day'},\n",
       " {'journal': 'title'},\n",
       " {'journal': 'isoabbreviation'}]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tree = lxml.html.fromstring(rexml)\n",
    "tagList = []\n",
    "for node in tree.iter('journal'):\n",
    "    newiterList = node.iterdescendants()\n",
    "#     newiterList = node.iterchildren()\n",
    "    for ni in enumerate(newiterList):\n",
    "        niDict = {}\n",
    "        niDict[ni[1].getparent().tag] = ni[1].tag\n",
    "        tagList.append(niDict)\n",
    "#         print(niDict)\n",
    "#         print(ni[1].tag)\n",
    "#         print(ni)\n",
    "#         print(ni[1].getparent().tag)\n",
    "#         tagList.append(ni[1].getparent().tag)\n",
    "# tagList = set(tagList)\n",
    "# tagList\n",
    "tagList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dict_keys(['journal']),\n",
       " dict_keys(['journal']),\n",
       " dict_keys(['journalissue']),\n",
       " dict_keys(['journalissue']),\n",
       " dict_keys(['journalissue']),\n",
       " dict_keys(['pubdate']),\n",
       " dict_keys(['pubdate']),\n",
       " dict_keys(['pubdate']),\n",
       " dict_keys(['journal']),\n",
       " dict_keys(['journal'])]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keysList = [t.keys() for t in tagList]\n",
    "keysList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mesh terms\n",
    "meshList = [elem.tag for elem in article.xpath('//journal/*')]\n",
    "msList = []\n",
    "for m in range(len(meshList)):\n",
    "    newDict = {}    \n",
    "    newDict[m] =  \"meshheading\"\n",
    "    msList.append(newDict)\n",
    "    msQList = article.xpath('//journal/*')  \n",
    "\n",
    "newerList = []\n",
    "newList = [elem.iterchildren() for elem in msQList]\n",
    "for n,nt in enumerate(newList):\n",
    "    b = [elem for elem in nt]   \n",
    "    tag_names = [elem.tag for elem in b]\n",
    "    unique_tag_names = list(set(tag_names))\n",
    "    newDict = {tag:[] for tag in unique_tag_names}\n",
    "    for elem in b:\n",
    "        newDict[elem.tag].append(elem.text_content())\n",
    "    newerList.append(newDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{},\n",
       " {'issue': ['43'],\n",
       "  'pubdate': ['                         2017                         Nov                         03                     '],\n",
       "  'volume': ['66']},\n",
       " {},\n",
       " {}]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newerList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume\n",
      "journalissue\n",
      "issue\n",
      "journalissue\n",
      "pubdate\n",
      "journalissue\n",
      "year\n",
      "pubdate\n",
      "month\n",
      "pubdate\n",
      "day\n",
      "pubdate\n"
     ]
    }
   ],
   "source": [
    "# tree = lxml.html.fromstring(rexml)\n",
    "tagList = []\n",
    "for node in tree.iter('journalissue'):\n",
    "#     print(node)\n",
    "#     print(dir(node))\n",
    "#     print(node.itertext)\n",
    "#     print(node.getnext())\n",
    "    newiterList = node.iterdescendants()\n",
    "    for ni in enumerate(newiterList):\n",
    "#         print(ni)\n",
    "        print(ni[1].tag)\n",
    "        print(ni[1].getparent().tag)\n",
    "        tagList.append(ni[1].getparent().tag)\n",
    "tagList = set(tagList)\n",
    "# tagList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'volume': '66'},\n",
       " {'issue': '43'},\n",
       " {'pubdate': '                         2017                         Nov                         03                     '}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issueDictList = []\n",
    "issueList = [elem for elem in article.xpath('//journal/journalissue/*')]\n",
    "for i in issueList:\n",
    "    iDict = {}\n",
    "    iDict[i.tag] = i.text_content()\n",
    "    issueDictList.append(iDict)\n",
    "issueDictList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element journalissue at 0x10907ed68>\n"
     ]
    }
   ],
   "source": [
    "for node in tree.iter('issue'):\n",
    "    print(node.getparent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lxml.etree.ElementDepthFirstIterator at 0x108d586c0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.getiterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method _Element.iterchildren of <Element issn at 0x109071548>>\n",
      "<bound method _Element.iterchildren of <Element journalissue at 0x1091e8bd8>>\n",
      "<bound method _Element.iterchildren of <Element title at 0x1091e8c78>>\n",
      "<bound method _Element.iterchildren of <Element isoabbreviation at 0x1091e8c28>>\n"
     ]
    }
   ],
   "source": [
    "# [elem.iterchildren for elem in article.xpath('//journal/journalissue/*')]\n",
    "jList = [elem.iterchildren for elem in article.xpath('//journal/*')]\n",
    "for j in jList:\n",
    "    print(j)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'volume': '66'},\n",
       " {'issue': '43'},\n",
       " {'pubdate': '                         2017                         Nov                         03                     '}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issueDictList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDS\n",
    "idList = [elem.attrib for elem in article.xpath('//articleidlist/articleid[@idtype]')]\n",
    "idDictList = []\n",
    "for i in idList:\n",
    "    for k,v in i.items():\n",
    "        newPath = '//articleidlist/articleid[@idtype = \"' + v + '\"]'\n",
    "        valsList = article.xpath(newPath)\n",
    "        for val in valsList:\n",
    "            idDict = {}\n",
    "            idDict[v] = val.text_content()\n",
    "            idDictList.append(idDict)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mesh terms\n",
    "meshList = [elem.tag for elem in article.xpath('//meshheadinglist/*')]\n",
    "msList = []\n",
    "for m in range(len(meshList)):\n",
    "    newDict = {}    \n",
    "    newDict[m] =  \"meshheading\"\n",
    "    msList.append(newDict)\n",
    "    msQList = article.xpath('//meshheadinglist/meshheading')  \n",
    "\n",
    "newerList = []\n",
    "newList = [elem.iterchildren() for elem in msQList]\n",
    "for n,nt in enumerate(newList):\n",
    "    b = [elem for elem in nt]   \n",
    "    tag_names = [elem.tag for elem in b]\n",
    "    unique_tag_names = list(set(tag_names))\n",
    "    newDict = {tag:[] for tag in unique_tag_names}\n",
    "    for elem in b:\n",
    "        newDict[elem.tag].append(elem.text_content())\n",
    "    newerList.append(newDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            d = {\n",
    "                        'title': title,\n",
    "                        'associatedId' : associatedId,\n",
    "                        'author': authList,    \n",
    "                        'journal' : journal,\n",
    "                        'pubtype': pubTypeVal,\n",
    "                        'publishdate': dateVal,\n",
    "                        'publishdatefull': dateDictVal,\n",
    "                        'meshterms': meshList,\n",
    "                        'abstract': abstractList,\n",
    "                        'optionalId01' : doi,\n",
    "                        'optionalId02': pmid\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  ArticleList = soup.find_all('PubmedArticle')\n",
    "            articleList = []\n",
    "\n",
    "            for article in ArticleList:\n",
    "                ssList = []\n",
    "\n",
    "                 ####### title ########\n",
    "                title = article.find('ArticleTitle').text\n",
    "\n",
    "                ####### pmid #########\n",
    "                associatedId = article.find('PMID').text\n",
    "\n",
    "                ####### journal ########\n",
    "                journal = article.find('Title').text   \n",
    "\n",
    "                ####### meshterms ##########\n",
    "\n",
    "                #each meshterm will have its word and possibly some qualifiernames\n",
    "                meshList = []\n",
    "\n",
    "                try:\n",
    "                    meshTermList = article.find_all('MeshHeading')\n",
    "                    for term in meshTermList:\n",
    "                        descriptorTerm = term.find('DescriptorName').text\n",
    "                        qualifierList = []\n",
    "                        try:\n",
    "                            qualifierNameList = term.find_all('QualifierName')\n",
    "                            for qual in qualifierNameList:\n",
    "                                thisQual = qual.text\n",
    "                                qualifierList.append(thisQual)\n",
    "                        except: \n",
    "                            qualifierList = None\n",
    "\n",
    "                        mtDict = {'term': descriptorTerm, 'qualList': qualifierList}\n",
    "                        meshList.append(mtDict)\n",
    "                except:\n",
    "                    meshList = None\n",
    "\n",
    "                ######## article date ###########\n",
    "\n",
    "                if article.find('ArticleDate'):\n",
    "                    year = article.find('DateCreated').find('Year').text\n",
    "                    month = article.find('DateCreated').find('Month').text\n",
    "                    day = article.find('DateCreated').find('Day').text\n",
    "                    dateDict = {'month':month,'year':year,'day':day}\n",
    "                    fulldate = '{0}/{1}/{2}'.format(month,day,year)\n",
    "                if not article.find('ArticleDate'):\n",
    "                    year = article.find('DateCreated').find('Year').text\n",
    "                    month = article.find('DateCreated').find('Month').text\n",
    "                    day = article.find('DateCreated').find('Day').text\n",
    "                    dateDict = {'month':month,'year':year,'day':day}\n",
    "                    fulldate = '{0}/{1}/{2}'.format(month,day,year)\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "                ######### pubtype ##########\n",
    "#                 pubTypeVal = \"\"\n",
    "#                 try:\n",
    "#                     pubTypes = article.find_all('PublicationType')\n",
    "#                     for pub in pubTypes:\n",
    "#                         try:\n",
    "#                             pubTypeVal = pub.text\n",
    "#                         except:\n",
    "#                             pubTypeVal = None   \n",
    "#                 except:\n",
    "#                     pubTypeVal = None\n",
    "\n",
    "                pubTypeVal = \"\"\n",
    "                try:\n",
    "                    pubTypes = article.find('PublicationType')\n",
    "                    pubTypeVal = pubTypes.text\n",
    "                except:\n",
    "                    pubTypeVal = None\n",
    "                    \n",
    "                    \n",
    "                ######### abstract ##########\n",
    "\n",
    "                abstractList = []\n",
    "                try:\n",
    "                    abstractText = article.find('Abstract')\n",
    "                    sections = abstractText.find_all('AbstractText')\n",
    "                    if sections[0].get('Label'):\n",
    "                        #broken up by nlm category\n",
    "                        for sec in sections:\n",
    "                            abstractDict = {}\n",
    "                            abstractDict['NlmCategory'] = sec.get('NlmCategory')\n",
    "                            abstractDict['Label'] = sec.get('Label')\n",
    "                            abstractDict['text'] = sec.text\n",
    "                            abstractList.append(abstractDict)\n",
    "                    if not sections[0].get('Label'):\n",
    "                        #comes as whole chunk\n",
    "                        abstractDict = {}\n",
    "                        abstractFull = abstractText.find('AbstractText').text\n",
    "                        abstractDict['wholetext'] = abstractFull\n",
    "                        abstractList.append(abstractDict)\n",
    "                except:\n",
    "                    #this means there is no abstract at all\n",
    "                    abstractList = None\n",
    "\n",
    "                ############ authors ###############\n",
    "\n",
    "                #each article will have a list of authors. Each author is represented by a dictionary (key values: fname, lname, affliation)\n",
    "                authList = []\n",
    "                #some articles don't have an author\n",
    "                try:          \n",
    "                    authorList = article.find('AuthorList')\n",
    "                    for author in authorList:\n",
    "                        try:\n",
    "                            affiliation = author.find('CollectiveName').text\n",
    "                            lname = None\n",
    "                            fname = None\n",
    "                        except:\n",
    "                            try:\n",
    "                                lname = author.find('LastName').text\n",
    "                            except:\n",
    "                                lname = None\n",
    "                            try:\n",
    "                                fname = author.find('ForeName').text\n",
    "                            except:\n",
    "                                fname = None\n",
    "                            try:\n",
    "                                affiliation = author.find('Affiliation').text\n",
    "                            except:\n",
    "                                affiliation = None\n",
    "                            authDict = {'lname':lname,'fname':fname, 'affl':affiliation}\n",
    "                            authList.append(authDict)\n",
    "\n",
    "                except:\n",
    "                    authList = None\n",
    "\n",
    "                ######### doi ##########\n",
    "                doi = None\n",
    "\n",
    "                try:\n",
    "                    doiList = article.find_all('ArticleId')\n",
    "\n",
    "                    for doiM in doiList:\n",
    "                        if doiM.get('IdType') == 'doi':\n",
    "                            doi = doiM.text\n",
    "                except:\n",
    "\n",
    "                    try:\n",
    "                        doiList = article.find_all('ELocationID')\n",
    "                        for doiM in doiList:\n",
    "                            if doiM.get('IdType') == 'doi':\n",
    "                                doi = doiM.text\n",
    "                    except:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
