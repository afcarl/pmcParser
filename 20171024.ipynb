{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Bio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dbfcd0147055>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mBio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEntrez\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Bio'"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "# import plotly as py\n",
    "import itertools\n",
    "import csv \n",
    "import urllib\n",
    "import codecs\n",
    "import io\n",
    "import sys\n",
    "import encodings\n",
    "# import chardet\n",
    "import unicodedata\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "from itertools import chain\n",
    "import pyodbc\n",
    "# import plotly.plotly as py\n",
    "# import plotly.tools as plotly_tools\n",
    "# from plotly.graph_objs import *\n",
    "# import plotly.figure_factory as ff\n",
    "from IPython.display import HTML\n",
    "from datetime import date\n",
    "import datetime\n",
    "import sqlalchemy\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import bindparam\n",
    "from datetime import datetime as dt\n",
    "import types\n",
    "\n",
    "# py.sign_in(\"jackp\", \"XXXX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create classes for fetching data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searchParams formats search parameters for NCBI and generates and idList\n",
    "class searchParams:\n",
    "    def __init__(self,email, db):\n",
    "        self.db = db\n",
    "        self.email = email\n",
    "        Entrez.email = email\n",
    "        if db == \"pubmed\":\n",
    "            self.__class__ = pubmedParams\n",
    "        elif db == 'pmc':\n",
    "            self.__class__ = pmcParams\n",
    "            \n",
    "            \n",
    "class pubmedParams(searchParams):   \n",
    "#in this case the term tags (e.g., TA) are the same for pubmed and PMC. but there are other tags that aren't the same.\n",
    "\n",
    "    def get_term(self,journalTerm,keyTerm,useTags):\n",
    "        \"\"\"return the search term concatenated with type ðŸ˜˜\"\"\"\n",
    "        journalType = '[TA]'\n",
    "        keyType = \"[ALL]\"\n",
    "        if useTags == 'No':\n",
    "            if journalTerm != \"\" and keyTerm != \"\":\n",
    "                term = journalTerm+\" AND \"+keyTerm\n",
    "            elif journalTerm != \"\" and keyTerm == \"\":\n",
    "                term = journalTerm\n",
    "            elif keyTerm != \"\" and journalTerm == \"\":\n",
    "                term = keyTerm\n",
    "        elif useTags == 'Yes':\n",
    "            if journalTerm != \"\" and keyTerm != \"\":\n",
    "                term = journalTerm+journalType+\" AND \"+keyTerm+ keyType\n",
    "            elif journalTerm != \"\" and keyTerm == \"\":\n",
    "                term = journalTerm+journalType\n",
    "            elif keyTerm != \"\" and journalTerm == \"\":\n",
    "                term = keyTerm+ keyType\n",
    "                \n",
    "        return(term)\n",
    "    \n",
    "    def get_count(self, term):\n",
    "        counthandle = Entrez.egquery(term = term)\n",
    "        record = Entrez.read(counthandle)\n",
    "        for row in record[\"eGQueryResult\"]:\n",
    "            if row['DbName'] == 'pubmed':\n",
    "                rowcount = row['Count']\n",
    "        counthandle.close()\n",
    "        return rowcount\n",
    "        \n",
    "        \n",
    "class pmcParams(searchParams):\n",
    "\n",
    "    def get_term(self,journalTerm,keyTerm,useTags):\n",
    "        \"\"\"return the search term concatenated with type\"\"\"\n",
    "        journalType = '[TA]'\n",
    "        keyType = \"[ALL]\"\n",
    "        if useTags == 'No':\n",
    "            if journalTerm != \"\" and keyTerm != \"\":\n",
    "                term = journalTerm+\" AND \"+keyTerm\n",
    "            elif journalTerm != \"\" and keyTerm == \"\":\n",
    "                term = journalTerm\n",
    "            elif keyTerm != \"\" and journalTerm == \"\":\n",
    "                term = keyTerm\n",
    "        elif useTags == 'Yes':\n",
    "            if journalTerm != \"\" and keyTerm != \"\":\n",
    "                term = journalTerm+journalType+\" AND \"+keyTerm+ keyType\n",
    "            elif journalTerm != \"\" and keyTerm == \"\":\n",
    "                term = journalTerm+journalType\n",
    "            elif keyTerm != \"\" and journalTerm == \"\":\n",
    "                term = keyTerm+ keyType\n",
    "        return(term)        \n",
    "    \n",
    "    \n",
    "    def get_count(self, term):\n",
    "        counthandle = Entrez.egquery(term = term)\n",
    "        record = Entrez.read(counthandle)\n",
    "        for row in record[\"eGQueryResult\"]:\n",
    "            if row['DbName'] == 'pmc':\n",
    "                rowcount = row['Count']\n",
    "        counthandle.close()\n",
    "        return rowcount\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NCBISearch fetches the data from NCBI and ouutputs a list of \"soups\" for parsing\n",
    "class NCBISearch:\n",
    "    def __init__(self, email, retmode = 'xml'):\n",
    "        self.email = email\n",
    "        self.retmode = retmode\n",
    "        Entrez.email = email\n",
    "\n",
    "        #function for retrieving and storing ids\n",
    "    def pub_search(self,term,db,recordCount,sort='relevance',chunksize = 500,sleeptime = 5):\n",
    "        \n",
    "        submitinterv = math.ceil(int(recordCount)/chunksize)\n",
    "        \n",
    "        #append to idlist\n",
    "        idlist = []\n",
    "\n",
    "        retstartc = 0\n",
    "        for i in range(submitinterv):\n",
    "            handle = Entrez.esearch(db=db, \n",
    "                                sort='relevance', \n",
    "                                retstart= retstartc,\n",
    "                                retmax=chunksize,\n",
    "                                retmode='xml', \n",
    "                                term=term)\n",
    "            idresults = Entrez.read(handle)\n",
    "            idlist += idresults['IdList']\n",
    "            time.sleep(sleeptime)\n",
    "            retstartc += chunksize\n",
    "            handle.close()\n",
    "                \n",
    "        return idlist\n",
    "    \n",
    "    \n",
    "    def pub_fetch(self, db, idList):\n",
    "        soupList = []\n",
    "        indices = [i for i, s in enumerate(idList)]\n",
    "        for i in indices:\n",
    "            ssHandle = Entrez.efetch(db=db,id = idList[i],sort='relevance', retstart= 0,retmax=300,\n",
    "                    retmode='xml')\n",
    "            ssHandle = io.TextIOWrapper(ssHandle.detach(), encoding='utf-8')\n",
    "            ssResults = ssHandle.read()\n",
    "            ssSoup = BeautifulSoup(ssResults, 'xml')\n",
    "            soupList.append(ssSoup)\n",
    "        return(soupList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<?xml version=\"1.0\"?>\\n<!DOCTYPE pmc-articleset PUBLIC \"-//NLM//DTD ARTICLE SET 2.0//EN\" \"https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd\">\\n<pmc-articleset>\\n<article xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" article-type=\"research-article\">\\n  <?properties open_access?>\\n  <front>\\n    <journal-meta>\\n      <journal-id journal-id-type=\"nlm-ta\">BMC Public Health</journal-id>\\n      <journal-id journal-id-type=\"iso-abbrev\">BMC Public Health</journal-id>\\n      <journal-title-group>\\n        <journal-title>BMC Public Health</journal-title>\\n      </journal-title-group>\\n      <issn pub-type=\"epub\">1471-2458</issn>\\n      <publisher>\\n        <publisher-name>BioMed Central</publisher-name>\\n        <publisher-loc>London</publisher-loc>\\n      </publisher>\\n    </journal-meta>\\n    <article-meta>\\n      <article-id pub-id-type=\"pmid\">28525991</article-id>\\n      <article-id pub-id-type=\"pmc\">5438549</article-id>\\n      <article-id pub-id-type=\"publisher-id\">4372</article-id>\\n      <article-id pub-id-type=\"doi\">10.1186/s12889-017-4372-y</article-id>\\n      <article-categories>\\n        <subj-group subj-group-type=\"heading\">\\n          <subject>Research Article</subject>\\n        </subj-group>\\n      </article-categories>\\n      <title-group>\\n        <article-title>Correcting for day of the week and public holiday effects: improving a national daily syndromic surveillance service for detecting public health threats</article-title>\\n      </title-group>\\n      <contrib-group>\\n        <contrib contrib-type=\"author\" corresp=\"yes\">\\n          <contrib-id contrib-id-type=\"orcid\">http://orcid.org/0000-0003-4038-7177</contrib-id>\\n          <name>\\n            <surname>Buckingham-Jeffery</surname>\\n            <given-names>Elizabeth</given-names>\\n          </name>\\n          <address>\\n            <email>E.Buckingham-Jeffery@manchester.ac.uk</email>\\n          </address>\\n          <xref ref-type=\"aff\" rid=\"Aff1\">1</xref>\\n          <xref ref-type=\"aff\" rid=\"Aff3\">3</xref>\\n        </contrib>\\n        <contrib contrib-type=\"author\">\\n          <name>\\n            <surname>Morbey</surname>\\n            <given-names>Roger</given-names>\\n          </name>\\n          <address>\\n            <email>Roger.Morbey@phe.gov.uk</email>\\n          </address>\\n          <xref ref-type=\"aff\" rid=\"Aff2\">2</xref>\\n        </contrib>\\n        <contrib contrib-type=\"author\">\\n          <name>\\n            <surname>House</surname>\\n            <given-names>Thomas</given-names>\\n          </name>\\n          <address>\\n            <email>thomas.house@manchester.ac.uk</email>\\n          </address>\\n          <xref ref-type=\"aff\" rid=\"Aff3\">3</xref>\\n        </contrib>\\n        <contrib contrib-type=\"author\">\\n          <name>\\n            <surname>Elliot</surname>\\n            <given-names>Alex J.</given-names>\\n          </name>\\n          <address>\\n            <email>Alex.Elliot@phe.gov.uk</email>\\n          </address>\\n          <xref ref-type=\"aff\" rid=\"Aff2\">2</xref>\\n        </contrib>\\n        <contrib contrib-type=\"author\">\\n          <name>\\n            <surname>Harcourt</surname>\\n            <given-names>Sally</given-names>\\n          </name>\\n          <address>\\n            <email>Sally.Harcourt@phe.gov.uk</email>\\n          </address>\\n          <xref ref-type=\"aff\" rid=\"Aff2\">2</xref>\\n        </contrib>\\n        <contrib contrib-type=\"author\">\\n          <name>\\n            <surname>Smith</surname>\\n            <given-names>Gillian E.</given-names>\\n          </name>\\n          <address>\\n            <email>Gillian.Smith@phe.gov.uk</email>\\n          </address>\\n          <xref ref-type=\"aff\" rid=\"Aff2\">2</xref>\\n        </contrib>\\n        <aff id=\"Aff1\"><label>1</label><institution-wrap><institution-id institution-id-type=\"ISNI\">0000 0000 8809 1613</institution-id><institution-id institution-id-type=\"GRID\">grid.7372.1</institution-id><institution>Centre for Complexity Science and Warwick Infectious Disease Epidemiology Research Centre, </institution><institution>University of Warwick, </institution></institution-wrap>Coventry, UK </aff>\\n        <aff id=\"Aff2\"><label>2</label>Real-time Syndromic Surveillance Team, National Infection Service, Public Health England, Birmingham, UK </aff>\\n        <aff id=\"Aff3\"><label>3</label><institution-wrap><institution-id institution-id-type=\"ISNI\">0000000121662407</institution-id><institution-id institution-id-type=\"GRID\">grid.5379.8</institution-id><institution/><institution>School of Mathematics, University of Manchester, </institution></institution-wrap>Manchester, UK </aff>\\n      </contrib-group>\\n      <pub-date pub-type=\"epub\">\\n        <day>19</day>\\n        <month>5</month>\\n        <year>2017</year>\\n      </pub-date>\\n      <pub-date pub-type=\"pmc-release\">\\n        <day>19</day>\\n        <month>5</month>\\n        <year>2017</year>\\n      </pub-date>\\n      <pub-date pub-type=\"collection\">\\n        <year>2017</year>\\n      </pub-date>\\n      <volume>17</volume>\\n      <elocation-id>477</elocation-id>\\n      <history>\\n        <date date-type=\"received\">\\n          <day>17</day>\\n          <month>8</month>\\n          <year>2016</year>\\n        </date>\\n        <date date-type=\"accepted\">\\n          <day>7</day>\\n          <month>5</month>\\n          <year>2017</year>\\n        </date>\\n      </history>\\n      <permissions>\\n        <copyright-statement>&#xA9; The Author(s). 2017</copyright-statement>\\n        <license license-type=\"OpenAccess\">\\n          <license-p>\\n<bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type=\"uri\" xlink:href=\"http://creativecommons.org/licenses/by/4.0/\">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type=\"uri\" xlink:href=\"http://creativecommons.org/publicdomain/zero/1.0/\">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>\\n        </license>\\n      </permissions>\\n      <abstract id=\"Abs1\">\\n        <sec>\\n          <title>Background</title>\\n          <p>As service provision and patient behaviour varies by day, healthcare data used for public health surveillance can exhibit large day of the week effects. These regular effects are further complicated by the impact of public holidays. Real-time syndromic surveillance requires the daily analysis of a range of healthcare data sources, including family doctor consultations (called general practitioners, or GPs, in the UK). Failure to adjust for such reporting biases during analysis of syndromic GP surveillance data could lead to misinterpretations including false alarms or delays in the detection of outbreaks.</p>\\n          <p>The simplest smoothing method to remove a day of the week effect from daily time series data is a 7-day moving average. Public Health England developed the working day moving average in an attempt also to remove public holiday effects from daily GP data. However, neither of these methods adequately account for the combination of day of the week and public holiday effects.</p>\\n        </sec>\\n        <sec>\\n          <title>Methods</title>\\n          <p>The extended working day moving average was developed. This is a further data-driven method for adding a smooth trend curve to a time series graph of daily healthcare data, that aims to take both public holiday and day of the week effects into account. It is based on the assumption that the number of people seeking healthcare services is a combination of illness levels/severity and the ability or desire of patients to seek healthcare each day. The extended working day moving average was compared to the seven-day and working day moving averages through application to data from two syndromic indicators from the GP in-hours syndromic surveillance system managed by Public Health England.</p>\\n        </sec>\\n        <sec>\\n          <title>Results</title>\\n          <p>The extended working day moving average successfully smoothed the syndromic healthcare data by taking into account the combined day of the week and public holiday effects. In comparison, the seven-day and working day moving averages were unable to account for all these effects, which led to misleading smoothing curves.</p>\\n        </sec>\\n        <sec>\\n          <title>Conclusions</title>\\n          <p>The results from this study make it possible to identify trends and unusual activity in syndromic surveillance data from GP services in real-time independently of the effects caused by day of the week and public holidays, thereby improving the public health action resulting from the analysis of these data.</p>\\n        </sec>\\n      </abstract>\\n      <kwd-group xml:lang=\"en\">\\n        <title>Keywords</title>\\n        <kwd>Syndromic surveillance</kwd>\\n        <kwd>Day-of-the-week effect</kwd>\\n        <kwd>Smoothing</kwd>\\n      </kwd-group>\\n      <funding-group>\\n        <award-group>\\n          <funding-source>\\n            <institution-wrap>\\n              <institution-id institution-id-type=\"FundRef\">http://dx.doi.org/10.13039/501100000266</institution-id>\\n              <institution>Engineering and Physical Sciences Research Council</institution>\\n            </institution-wrap>\\n          </funding-source>\\n        </award-group>\\n        <award-group>\\n          <funding-source>\\n            <institution-wrap>\\n              <institution-id institution-id-type=\"FundRef\">http://dx.doi.org/10.13039/501100000272</institution-id>\\n              <institution>National Institute for Health Research</institution>\\n            </institution-wrap>\\n          </funding-source>\\n        </award-group>\\n      </funding-group>\\n      <custom-meta-group>\\n        <custom-meta>\\n          <meta-name>issue-copyright-statement</meta-name>\\n          <meta-value>&#xA9; The Author(s) 2017</meta-value>\\n        </custom-meta>\\n      </custom-meta-group>\\n    </article-meta>\\n  </front>\\n  <body>\\n    <sec id=\"Sec1\">\\n      <title>Background</title>\\n      <p>Syndromic surveillance is the near real-time collection, analysis, interpretation, and dissemination of health related data to enable the early identification of the impact of potential public health threats [<xref ref-type=\"bibr\" rid=\"CR1\">1</xref>]. The real-time syndromic surveillance team at Public Health England (PHE) co-ordinates a suite of syndromic surveillance systems in order to provide early warning of outbreaks of infectious disease, situational awareness during a public health incident, and reassurance of lack of impact [<xref ref-type=\"bibr\" rid=\"CR2\">2</xref>&#x2013;<xref ref-type=\"bibr\" rid=\"CR5\">5</xref>]. These syndromic surveillance systems are used to complement and support existing public health surveillance programmes.</p>\\n      <p>Line graphs of time series data offer a simple and effective way to review data and undertake exploratory analysis [<xref ref-type=\"bibr\" rid=\"CR6\">6</xref>, <xref ref-type=\"bibr\" rid=\"CR7\">7</xref>]. They are used, in addition to automated statistical alarms, by the real-time syndromic surveillance team to investigate, interpret, and present the current trends in syndromic data and for comparisons of the current data with previous years to identify changes from the norm. Regular, large fluctuations at small time-scales can, however, make it difficult to identify longer time-period trends in time series graphs. These difficulties can be overcome by adding to the graph a smooth trend curve which takes into account these known day-to-day fluctuations [<xref ref-type=\"bibr\" rid=\"CR8\">8</xref>].</p>\\n      <p>The <italic>GP in-hours syndromic surveillance system</italic> (GP in-hours SSS) monitors the number of in-hours family doctor (known as general practitioner, or GP, in the UK) consultations [<xref ref-type=\"bibr\" rid=\"CR9\">9</xref>]. Daily data on the number of GP consultations are analysed, and are aggregated into <italic>syndromic indicators</italic> based on symptoms and clinical diagnoses (e.g. influenza-like illness, diarrhoea, chickenpox) [<xref ref-type=\"bibr\" rid=\"CR9\">9</xref>]. Although much of the GP in-hours SSS is automated, statistical alarms are created that require manual, in-depth investigation [<xref ref-type=\"bibr\" rid=\"CR10\">10</xref>]. Effective data visualisations must be used in order for the manual investigation stage not to become the bottleneck of the real-time data analysis process [<xref ref-type=\"bibr\" rid=\"CR11\">11</xref>].</p>\\n      <p>Graphs of the syndromic indicators from the GP in-hours SSS are presented to the public and wider audiences in weekly bulletins published by PHE [<xref ref-type=\"bibr\" rid=\"CR12\">12</xref>]. This is an additional reason to ensure that the current trend in illness levels can be clearly interpreted from the graph without additional data or expert knowledge.</p>\\n      <p>Regular fluctuations at a weekly time-scale, known as <italic>day of the week effects</italic>, have been observed in the number of patient consultations with GP services [<xref ref-type=\"bibr\" rid=\"CR10\">10</xref>]. The number of consultations is also observed to regularly change on a public holiday and on the days immediately after [<xref ref-type=\"bibr\" rid=\"CR10\">10</xref>]. We refer to this as a <italic>public holiday effect.</italic>\\n</p>\\n      <p>The purpose of syndromic surveillance is to identify abnormally elevated disease levels as early as possible so that action can be taken to minimise the problem [<xref ref-type=\"bibr\" rid=\"CR13\">13</xref>, <xref ref-type=\"bibr\" rid=\"CR14\">14</xref>]. However, if the systematic changes in the number of consultations with GPs due to day of the week and public holidays are not accounted for, they could mask real increases in disease levels, create false alarms, and delay decision making over public holiday periods as more data are required to understand the current trend. It is important to try to distinguish the expected changes in consultation numbers due to day of the week or public holiday effects from unexpected changes due to potential public health threats.</p>\\n      <p>The purpose of this work is to develop and explore an appropriate smoothing method that takes the expected day of the week and public holiday effects into account simultaneously and displays no trend due to these predictable variations. This method will be applied to time series graphs to enhance visual analysis of daily GP consultation data for syndromic surveillance. This will improve daily risk assessments by epidemiological investigators.</p>\\n      <p>Data from healthcare services reflect the time at which patients sought healthcare advice. This does not necessarily correspond with date of symptom onset. In particular, patients with milder illnesses may not present unless they become more severe or complications develop [<xref ref-type=\"bibr\" rid=\"CR15\">15</xref>, <xref ref-type=\"bibr\" rid=\"CR16\">16</xref>]. Therefore, the number of healthcare consultations is not a simple measure of illness in the population but rather a combination of illness levels, severity of the illness, availability of healthcare services, and ability or willingness to seek healthcare [<xref ref-type=\"bibr\" rid=\"CR17\">17</xref>]. Based on this, we develop a data-driven smoothing method, the <italic>extended working day moving average,</italic> using scaling factors to take both day of the week and public holiday effects into account.</p>\\n      <p>The rest of this paper is organised as follows. The&#xA0;Background will conclude with a short discussion of the existing literature of smoothing methods to account for day of the week and public holiday effects in healthcare data, a description of the specific calendar effects observed in the GP in-hours SSS, and a description of the seven-day and working day moving average. The limitations of these methods justify the development of the extended working day moving average to take day of the week and public holiday effects into account simultaneously, which will be described in the&#xA0;Methods section. This will be followed by a description of the data from the GP in-hours SSS to which the smoothing methods will be applied. An evaluation of the extended working day moving average, with comparison to the seven-day and working day moving averages will be presented in the&#xA0;Results section. Finally, the strengths and limitations of the smoothing methods and the impact of using the extended working day moving average on public health practice will be discussed.</p>\\n      <sec id=\"Sec2\">\\n        <title>Existing literature of smoothing methods to account for day of the week and public holiday effects in healthcare data</title>\\n        <p>Smoothing to remove day of the week effects and visualise trends has been noted as being important for analysis of healthcare data [<xref ref-type=\"bibr\" rid=\"CR18\">18</xref>&#x2013;<xref ref-type=\"bibr\" rid=\"CR22\">22</xref>], although few smoothing methodologies have specifically been developed to enhance visual interpretations in this context. However, both model-based and data-driven smoothing methods have been used to remove day of the week and/or public holiday effects as part of more complex detection algorithms [<xref ref-type=\"bibr\" rid=\"CR17\">17</xref>].</p>\\n        <p>Many published methodologies are able to smooth day of the week effects but do not consider public holiday effects [<xref ref-type=\"bibr\" rid=\"CR17\">17</xref>, <xref ref-type=\"bibr\" rid=\"CR22\">22</xref>, <xref ref-type=\"bibr\" rid=\"CR23\">23</xref>]. However, this study will demonstrate that both day of the week and public holiday effects must be considered simultaneously to enable continued, effective surveillance of GP consultation data during and around public holidays.</p>\\n        <p>The working day moving average was developed by PHE to visualise trends in syndromic data from the GP in-hours SSS, however this has not previously been described in the literature.</p>\\n      </sec>\\n      <sec id=\"Sec3\">\\n        <title>Day of the week and public holiday effects in the GP in-hours SSS</title>\\n        <p>In the GP in-hours SSS more consultations occur on Monday than on any other day of the week. There were typically fewer consultations on each of Tuesday through Friday, and a negligible number of consultations on weekends. Figure <xref rid=\"Fig1\" ref-type=\"fig\">1</xref> displays, as examples, the proportion of the week&#x2019;s consultations (Monday &#x2013; Sunday) on each day of the week, for the severe asthma and gastroenteritis indicators. On all public holidays there were a negligible number of consultations (Fig. <xref rid=\"Fig1\" ref-type=\"fig\">1</xref>), and the first working day after a public holiday typically had a higher number of consultations than expected for the day of the week.<fig id=\"Fig1\"><label>Fig. 1</label><caption><p>Box plots of data from the GP in-hours syndromic surveillance system demonstrating the day of the week and public holiday effects for the (<bold>a</bold>) severe asthma indicator and (<bold>b</bold>) gastroenteritis indicator. Daily consultation numbers for each day between 2nd April 2012 and 11th January 2015 were grouped into weeks from Monday to Sunday and&#xA0;the proportion of the week\\'s consultations on each day of the week are summarised in the box plots</p></caption><graphic xlink:href=\"12889_2017_4372_Fig1_HTML\" id=\"MO1\"/></fig>\\n</p>\\n      </sec>\\n      <sec id=\"Sec4\">\\n        <title>Description of smoothing methods used for comparisons</title>\\n        <p>A 7-day moving average is the simplest data-driven smoothing approach to remove a day of the week effect. No adjustment is made for public holiday effects in this method.</p>\\n        <p>A moving average is a series of averages of subsets of the time series of syndromic data. The first element of a 7-day moving average is the average of the first seven data points. The second element is the average of the second to eighth data point. This is continued so that each set of seven consecutive data points is averaged [<xref ref-type=\"bibr\" rid=\"CR24\">24</xref>]. Seven days was chosen in this context as day of the week effects have 7-day periodicity.</p>\\n        <p>The working day moving average method was previously developed by PHE to take both day of the week and public holiday effects into account when visualising data from syndromic surveillance systems. This simple adjustment of the 7-day moving average aims to take into account public holidays and ensure the smoothing line takes values similar to the number of consultations on an average working day.</p>\\n        <p>The working day moving average is constructed as follows. Due to reduced opening hours, very few routine in-hours GP consultations occur on public holidays. Therefore, public holidays are grouped with weekends, and a moving average is computed that takes into account the number of working days. Let <italic>n</italic> denote the number of working days within the current block of 7 days being considered to give an element of the moving average. In the GP in-hours SSS this is typically five, as doctors&#x2019; surgeries do not typically open on weekends. However, in blocks containing public holidays it will be fewer. Instead of simply computing the average of the number of consultations on the 7 days, the sum of the number of consultations on working days was multiplied by <inline-formula id=\"IEq1\"><alternatives><tex-math id=\"M1\">\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym} \\n\\t\\t\\t\\t\\\\usepackage{amsfonts} \\n\\t\\t\\t\\t\\\\usepackage{amssymb} \\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$ \\\\frac{5}{n} $$\\\\end{document}</tex-math><mml:math id=\"M2\" display=\"inline\"><mml:mfrac><mml:mn>5</mml:mn><mml:mi>n</mml:mi></mml:mfrac></mml:math><inline-graphic xlink:href=\"12889_2017_4372_Article_IEq1.gif\"/></alternatives></inline-formula> and the sum of the number of consultations on non-working days was multiplied by <inline-formula id=\"IEq2\"><alternatives><tex-math id=\"M3\">\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym} \\n\\t\\t\\t\\t\\\\usepackage{amsfonts} \\n\\t\\t\\t\\t\\\\usepackage{amssymb} \\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$ \\\\frac{2}{7- n} $$\\\\end{document}</tex-math><mml:math id=\"M4\" display=\"inline\"><mml:mfrac><mml:mn>2</mml:mn><mml:mrow><mml:mn>7</mml:mn><mml:mo>&#x2212;</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href=\"12889_2017_4372_Article_IEq2.gif\"/></alternatives></inline-formula>. The sum of these totals was then divided by five, the typical number of working days in the GP in-hours SSS.</p>\\n        <p>For a block of 7 days with no public holidays, this calculation just gives <inline-formula id=\"IEq3\"><alternatives><tex-math id=\"M5\">\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym} \\n\\t\\t\\t\\t\\\\usepackage{amsfonts} \\n\\t\\t\\t\\t\\\\usepackage{amssymb} \\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$ \\\\frac{1}{5} $$\\\\end{document}</tex-math><mml:math id=\"M6\" display=\"inline\"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>5</mml:mn></mml:mfrac></mml:math><inline-graphic xlink:href=\"12889_2017_4372_Article_IEq3.gif\"/></alternatives></inline-formula> times the sum of the number of consultations on the 7 days in question, a basic moving average. For blocks of 7 days containing public holidays, this calculation weights the working days slightly more than the simple sum and the non-working days slightly less. This accounts for the expected reduction in total consultations in the week due to the public holiday.</p>\\n      </sec>\\n    </sec>\\n    <sec id=\"Sec5\">\\n      <title>Methods</title>\\n      <sec id=\"Sec6\">\\n        <title>Extended working day moving average</title>\\n        <p>In the extended working day moving average, we do not simply assume that healthcare seeking behaviour on public holidays is the same as on weekend days and that behaviour on all other weekdays is the same. Instead, each different day of the week and each day affected by a public holiday is assigned a scaling factor. This simultaneously takes into account changes in the number of healthcare consultations on days surrounding public holidays, changes in the number of consultations on the public holiday itself, and the day of the week effect.</p>\\n        <p>Data from one complete year, excluding any weeks containing public holidays, were used to give the scaling factors of the extended working day moving average for a syndromic indicator from the GP in-hours SSS. Therefore, the scaling factors will be different for each syndromic indicator.</p>\\n        <p>In order to compute the scaling factors, the proportion of each week&#x2019;s activity (Monday &#x2013; Sunday) on each day was calculated. These were averaged over all weeks not containing public holidays to give an average proportion of the weekly activity on each day of the week. These average proportions were multiplied by five, the number of working days in a typical week in the GP in-hours SSS, to give the initial scaling factors. Additional scaling factors were developed based on the public holiday effects. Each public holiday was assigned the same scaling factor as a typical Sunday, and the first working day after a public holiday was given the same scaling factor as a typical Monday. These scaling factors reflect the typical number of consultations on each day of the week; a value larger than one reflects a day with typically a higher than average number of consultations.</p>\\n        <p>To construct the extended working day moving average, the sum of each 7-day block was divided by the sum of the corresponding scaling factors. Note that the extended working day moving average for a 7-day block without a public holiday is simply the sum of consultations divided by five, giving a basic moving average during these periods.</p>\\n      </sec>\\n      <sec id=\"Sec7\">\\n        <title>Data</title>\\n        <p>The extended working day moving average has been developed for smoothing data from the GP in-hours SSS. However, the dynamics of the diseases that generate the syndromic data are complex, and the recorded activity levels are affected by system coverage fluctuations, data collection changes, and other unknown influences on top of the day of the week and public holidays effects [<xref ref-type=\"bibr\" rid=\"CR10\">10</xref>]. This can make it difficult to clearly compare and evaluate the different smoothing methods. Therefore, they were first applied to synthetic data with the same public holiday and day of the week effects as the GP in-hours SSS but without longer-term trends and noise.</p>\\n        <p>We constructed synthetic data for a period of 4 weeks. Based on historic data, we considered a total of 2900 consultations per week and split this into 696 consultations on Monday (24% of the week&#x2019;s consultations), 522 (18%) on each of Tuesday to Friday, and 58 (2%) on weekend days. In order to incorporate a public holiday effect, the third Monday of the synthetic data was denoted as a public holiday. This day was given the same number of consultations as a Sunday (58 consultations, or 2.4% of the public holiday week&#x2019;s consultations). The Tuesday immediately after was given the same number of consultations as the typical Mondays (696 consultations, or 28.6%). The number of consultations on all other days in this week was left unchanged (522, or 21.4%, on the remaining weekdays and 52, or 2.4%, on the weekend days). There were fewer consultations overall in the week containing the public holiday. The synthetic data are presented in Fig. <xref rid=\"Fig2\" ref-type=\"fig\">2</xref>.<fig id=\"Fig2\"><label>Fig. 2</label><caption><p>The extended working day moving average applied to synthetic data, with the seven-day and working day moving averages for comparison. Synthetic data were generated for 28&#xA0;days, containing day of the week and public holiday effects representative of those observed in the GP in-hours syndromic surveillance system, but without noise and longer term trends. The synthetic data included a public holiday Monday. This is indicated by the grey vertical line and easily identifiable by the negligible number of consultations on this day. The extended working day moving average was applied to this data with the seven-day and working day moving average shown for comparison. The <italic>red box</italic> highlights the pre- and post- public holiday period of interest</p></caption><graphic xlink:href=\"12889_2017_4372_Fig2_HTML\" id=\"MO2\"/></fig>\\n</p>\\n        <p>The smoothing methods were also applied to actual data from the GP in-hours SSS for 52&#xA0;weeks, from 13th January 2014 to 11th January 2015. The indicators severe asthma and gastroenteritis were chosen as examples. Other syndromic indicators could have been used; similar day of the week and public holiday effects are extensively observed across the system.</p>\\n      </sec>\\n    </sec>\\n    <sec id=\"Sec8\">\\n      <title>Results</title>\\n      <p>As previously described, the extended working day moving average was applied to synthetic data and the severe asthma and gastroenteritis syndromic indicators from the GP in-hours SSS. The 7-day and working day moving averages were also applied for comparison.</p>\\n      <p>Using the percentages 2%, 18%, and 24% described in the <xref rid=\"Sec7\" ref-type=\"sec\">Data</xref> section, the scaling factors for the extended working day moving average applied to the synthetic data were calculated as 0.1 for weekends and public holidays, 1.2 for typical Mondays and the first working day after a public holiday, and 0.9 for all other typical weekdays. The scaling factors calculated from the severe asthma and gastroenteritis indicator data are given in Table <xref rid=\"Tab1\" ref-type=\"table\">1</xref>.<table-wrap id=\"Tab1\"><label>Table 1</label><caption><p>Scaling factors for indicators from the GP in-hours syndromic surveillance system for the extended working day moving average</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th/><th>Scaling factors: severe asthma</th><th>Scaling factors: gastroenteritis</th></tr></thead><tbody><tr><td>Monday</td><td>1.30</td><td>1.25</td></tr><tr><td>Tuesday</td><td>0.95</td><td>0.95</td></tr><tr><td>Wednesday</td><td>0.91</td><td>0.91</td></tr><tr><td>Thursday</td><td>0.87</td><td>0.90</td></tr><tr><td>Friday</td><td>0.93</td><td>0.95</td></tr><tr><td>Saturday</td><td>0.03</td><td>0.02</td></tr><tr><td>Sunday</td><td>0.01</td><td>0.01</td></tr><tr><td>Public holiday</td><td>0.01</td><td>0.01</td></tr><tr><td>First working day after public holiday</td><td>1.30</td><td>1.25</td></tr></tbody></table><table-wrap-foot><p>The scaling factors for the extended working day moving average for Monday &#x2013; Sunday were based on 52&#xA0;weeks of data (13th January 2014 - 11th January 2015) using the method outlined in the main text. The scaling factors for public holidays and their surrounding days were based on observations made of the GP in-hours syndromic surveillance system over multiple years</p></table-wrap-foot></table-wrap>\\n</p>\\n      <p>The extended working day moving average showed a no-trend line when applied to the synthetic data, as the combination of day of the week and public holiday effects were taken into account (Fig. <xref rid=\"Fig2\" ref-type=\"fig\">2</xref>). The extended working day moving average also continued to display the trends in the syndromic data throughout public holiday periods (Fig. <xref rid=\"Fig3\" ref-type=\"fig\">3</xref>).<fig id=\"Fig3\"><label>Fig. 3</label><caption><p>The number of (<bold>a</bold>) severe asthma and (<bold>b</bold>) gastroenteritis consultations from the GP in-hours syndromic surveillance system with the extended working day moving average. The seven-day and working day moving averages are also included for comparison. The grey vertical lines indicate public holidays. The <italic>red boxes</italic> highlight the pre- and post- Monday public holiday dips and peaks in the seven-day and working day moving average and their removal in the extended working day moving average</p></caption><graphic xlink:href=\"12889_2017_4372_Fig3_HTML\" id=\"MO3\"/></fig>\\n</p>\\n      <p>In the absence of public holidays, the seven-day moving average applied to the synthetic data smoothed the regular day of the week effect to highlight the current trend. However, there is a dip in the smoothing trend curve for 7 days around the public holiday (Fig. <xref rid=\"Fig2\" ref-type=\"fig\">2</xref>). These synthetic data followed the expected behaviour of no-trend syndromic data around a public holiday. With real data, this dip in the smoothing curve could mask an actual increase in disease levels over this time period. However, this change is entirely expected due to the change in healthcare service provision on public holidays. Additionally, the 7-day moving average was lower than the average number of consultations on a working day. It is more useful that the smooth trend curve gives an indication of the number of healthcare contacts on a typical working day.</p>\\n      <p>These same results were also observed when the 7-day moving average was applied to surveillance data for the severe asthma and gastroenteritis indicators (Fig. <xref rid=\"Fig3\" ref-type=\"fig\">3</xref>).</p>\\n      <p>The working day moving average applied to synthetic data gave a better smooth curve than the 7-day moving average (Fig. <xref rid=\"Fig2\" ref-type=\"fig\">2</xref>). However, a drop 3 days before and a peak 4 days after public holidays were still present in the smoothing curve when applied to both synthetic and real data (Figs. <xref rid=\"Fig2\" ref-type=\"fig\">2</xref> and <xref rid=\"Fig3\" ref-type=\"fig\">3</xref>).&#xA0;These were due to the combination of the day of the week and public holiday effects. The drop was caused by that 7-day sum not including a typical Monday, and the peak was caused by that 7-day sum including both a typical Monday and the elevated Tuesday directly after the public holiday.</p>\\n      <p>In the absence of big day of the week effects, the working day moving average would smooth a simple public holiday effect. However, the interaction between day of the week and public holiday effects, and extended holiday effects such as a change in activity on the first working day after a public holiday, are not accounted for.</p>\\n      <p>Smoothing trend curves are used to help investigators visually identify current unusual activity during daily surveillance of syndromic disease data. It is easy to retrospectively look at the smoothing curve given by the working day moving average and identify the spikes as clearly spurious due to their short duration. However, in order to emphasise how misleading the 7-day and working day moving averages can be we applied all the smoothing methods to the dataset that would be available a week after a Monday public holiday. This graph would be used to assess the current trend in the number of severe asthma consultations (Fig. <xref rid=\"Fig4\" ref-type=\"fig\">4</xref>). The trend 1 week after a public holiday would be noted as increasing if either the 7-day or working day moving averages were used. This could lead to unnecessary alarm. The extended working day moving average did not show an increasing trend and, more importantly, neither did the data. The extended working day moving average would make it easier for investigators to identify unusual activity during this period.<fig id=\"Fig4\"><label>Fig. 4</label><caption><p>A comparison of the current trend given by each of the smoothing methods for the severe asthma indicator from the GP in-hours syndromic surveillance system. This graph displays the data that is available 1 week after a Monday public holiday (public holidays indicated by <italic>grey vertical lines</italic>). A smoothing method would be used to display the current trend (the area of interest inside the <italic>red&#xA0;box</italic>). Both the seven-day and working day moving averages show a currently increasing trend. The extended working day moving average and, importantly, the data do not</p></caption><graphic xlink:href=\"12889_2017_4372_Fig4_HTML\" id=\"MO4\"/></fig>\\n</p>\\n    </sec>\\n    <sec id=\"Sec9\">\\n      <title>Discussion</title>\\n      <p>It is widely acknowledged that day of the week and public holiday effects exist in healthcare data used for syndromic surveillance and that this can disguise anomalies in the data when visually inspecting it [<xref ref-type=\"bibr\" rid=\"CR10\">10</xref>, <xref ref-type=\"bibr\" rid=\"CR17\">17</xref>&#x2013;<xref ref-type=\"bibr\" rid=\"CR23\">23</xref>]. In this study, we described the previous smoothing method used by PHE to smooth data from the GP in-hours SSS. We also developed a smoothing method where both day of the week and public holiday effects are taken into account simultaneously. We demonstrated how the extended working day moving average can be used to aid interpretation of the trends in real-time syndromic surveillance data from GP services, thereby improving the public health action resulting from the analysis. The extended working day moving average method retains the ability to display unusual changes in the trends of syndromic indicators from the GP in-hours SSS during public holiday periods, and it removes the potentially misleading spikes observed in the working day moving average. This reduces the potential for delays in the detection of public health threats during this time.</p>\\n      <p>The inter-quartile ranges of the proportion of consultations on each day of the week are quite narrow (Fig. <xref rid=\"Fig1\" ref-type=\"fig\">1</xref>). This indicates that the day of the week effect is consistent throughout the year. However, day of the week and public holiday effects are just one cause of noise in these complex data sets. The number of GP consultations fluctuates and contains regular trends due to other factors that we do not discuss or control for here. These include, for example, seasonal disease outbreaks and changes in the data collection systems.</p>\\n      <p>In this study only relatively simple data-driven smoothing methods were considered. Syndromic surveillance uses large, varied data sets, and it is desirable for syndromic surveillance reporting systems to be as automated as possible. A simple data-driven smoothing approach ensures sufficient flexibility so that smoothing methods can be applied to a wide range of indicators in an automated way [<xref ref-type=\"bibr\" rid=\"CR25\">25</xref>]. As discussed in the Background, data-driven smoothing methods have previously been used to remove day of the week and/or public holiday effects from daily syndromic data as part of more complex detection algorithms [<xref ref-type=\"bibr\" rid=\"CR17\">17</xref>, <xref ref-type=\"bibr\" rid=\"CR20\">20</xref>, <xref ref-type=\"bibr\" rid=\"CR26\">26</xref>, <xref ref-type=\"bibr\" rid=\"CR27\">27</xref>]. However, this study shows that both day of the week and public holiday effects must be considered simultaneously to create adequately smooth daily healthcare data. We have addressed this problem in the context of GP in-hours consultation data used for daily syndromic surveillance in England, and we have focused on methods to improve time series graphs used for daily risk assessments by investigators.</p>\\n      <p>The extended working day moving average was developed for the GP in-hours SSS coordinated by PHE. We demonstrated the method applied to the gastroenteritis and severe asthma indicators as examples. However, the day of the week and public holiday effects observed in these two indicators are also observed across the GP in-hours SSS in a consistent way (see, for example, the plots of data for a large number of indicators within the PHE weekly bulletin [<xref ref-type=\"bibr\" rid=\"CR12\">12</xref>]). It is therefore appropriate and straightforward to apply the method to other syndromic indicators from the GP in-hours SSS, and we see the same results as discussed here. As a result of this, the extended working day moving average is now in use across the GP in-hours SSS.</p>\\n      <p>Day of the week or public holiday effects are also seen in attendance data from many other healthcare services. This includes emergency departments [<xref ref-type=\"bibr\" rid=\"CR28\">28</xref>], walk-in clinics [<xref ref-type=\"bibr\" rid=\"CR29\">29</xref>], military treatment facilities [<xref ref-type=\"bibr\" rid=\"CR15\">15</xref>], sexual health clinics [<xref ref-type=\"bibr\" rid=\"CR30\">30</xref>], telehealth services [<xref ref-type=\"bibr\" rid=\"CR5\">5</xref>], and internet based symptom-checker services [<xref ref-type=\"bibr\" rid=\"CR31\">31</xref>]. It is also seen in the other syndromic surveillance systems operated by PHE. This work has demonstrated the importance of being aware of day of the week and public holiday effects in analysis and interpretation of this type of data, including the effect on days near to the public holiday itself. We have shown how an inadequate treatment of these effects can lead to potential confusion in the current trend and delay decision making.</p>\\n      <p>However, the extended working day moving average described here was developed for use with just one particular syndromic surveillance system. Further work is needed to investigate whether the extended working day moving average could be applied to other surveillance systems. In particular, whether it is valid for those which monitor attendances at 7-day healthcare services. Additionally, if the day of the week and public holiday effects are not as large as those observed in the GP in-hours SSS a simpler method could be sufficient. Further work in this area will describe the extent of the day of the week and public holiday effects across different syndromic surveillance systems. This will also involve an investigation of the public health aspects of these effects, rather than purely the statistical approaches considered during this analysis.</p>\\n      <p>The main limitation of the extended working day moving average is that historical data are needed to compute the scaling factors. In particular, sufficient data are required to learn how the number of consultations changes around each public holiday. On the other hand, the working day moving average and 7-day moving average do not require historical data and therefore can be used immediately with new syndromic surveillance systems.</p>\\n    </sec>\\n    <sec id=\"Sec10\">\\n      <title>Conclusions</title>\\n      <p>Our results show that basic smoothing techniques are not able to account fully for the public holiday effects observed in the GP in-hours SSS. We have developed and demonstrated an improved smoothing technique that can make it easier for investigators to identify unusual activity during daily surveillance of syndromic GP data. This method is now in use in the GP in-hours SSS at PHE. It has led to enhanced visualisations of this data during the analysis phase and in weekly public health bulletins [<xref ref-type=\"bibr\" rid=\"CR12\">12</xref>].</p>\\n      <p>Based on this study, it is recommended that analysis and visualisation methods for syndromic data carefully take both day of the week and public holiday effects into account.</p>\\n    </sec>\\n  </body>\\n  <back>\\n    <glossary>\\n      <title>Abbreviations</title>\\n      <def-list>\\n        <def-item>\\n          <term>GP</term>\\n          <def>\\n            <p>General practitioner</p>\\n          </def>\\n        </def-item>\\n        <def-item>\\n          <term>PHE</term>\\n          <def>\\n            <p>Public Health England</p>\\n          </def>\\n        </def-item>\\n        <def-item>\\n          <term>SSS</term>\\n          <def>\\n            <p>Syndromic surveillance system</p>\\n          </def>\\n        </def-item>\\n      </def-list>\\n    </glossary>\\n    <ack>\\n      <title>Acknowledgements</title>\\n      <p>We acknowledge support from TPP and participating SystmOne practices and University of Nottingham, ClinRisk, EMIS and EMIS practices submitting data to the QSurveillance database. We thank the PHE Real-time Syndromic Surveillance Team for technical expertise.</p>\\n      <sec id=\"FPar1\">\\n        <title>Funding</title>\\n        <p>EB-J&#x2019;s PhD is funded by the Engineering and Physical Sciences Research Council&#xA0;[grants EP/I01358X/1 and EP/N033701/1]. TH is supported by the Engineering and Physical Sciences Research Council&#xA0;[grants EP/J002437/1 and EP/N033701/1]. RM, AJE and GES receive support from the National Institute for Health Research Health Protection Research Unit (NIHR HPRU) in Emergency Preparedness and Response. The views expressed are those of the authors and not necessarily those of the NHS, the NIHR, the Department of Health, or Public Health England.</p>\\n      </sec>\\n      <sec id=\"FPar2\">\\n        <title>Availability of data and materials</title>\\n        <p>The data used in this study (presented in Figs. <xref rid=\"Fig1\" ref-type=\"fig\">1</xref>, <xref rid=\"Fig3\" ref-type=\"fig\">3</xref> and <xref rid=\"Fig4\" ref-type=\"fig\">4</xref>) are covered by governance and contractual agreements that limit their use for Public Health England surveillance activities only, and are therefore not available for sharing.</p>\\n      </sec>\\n      <sec id=\"FPar3\">\\n        <title>Authors&#x2019; contributions</title>\\n        <p>EB-J developed the methodology, performed the analysis, drafted the manuscript. RM designed the study, developed the methodology, revised the manuscript. TH developed the methodology, revised the manuscript. AE, SH, GS designed the study, revised the manuscript. All authors approved the final manuscript.</p>\\n      </sec>\\n      <sec id=\"FPar4\">\\n        <title>Competing interests</title>\\n        <p>The authors declare that they have no competing interests.</p>\\n      </sec>\\n      <sec id=\"FPar5\">\\n        <title>Consent for publication</title>\\n        <p>Not applicable.</p>\\n      </sec>\\n      <sec id=\"FPar6\">\\n        <title>Ethics approval and consent to participate</title>\\n        <p>Not applicable.</p>\\n      </sec>\\n      <sec id=\"FPar7\">\\n        <title>Publisher&#x2019;s Note</title>\\n        <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>\\n      </sec>\\n    </ack>\\n    <ref-list id=\"Bib1\">\\n      <title>References</title>\\n      <ref id=\"CR1\">\\n        <label>1.</label>\\n        <element-citation publication-type=\"journal\">\\n          <person-group person-group-type=\"author\">\\n            <collab>Triple S Project</collab>\\n          </person-group>\\n          <article-title>Assessment of syndromic surveillance in Europe</article-title>\\n          <source>Lancet</source>\\n          <year>2011</year>\\n          <volume>378</volume>\\n          <issue>9806</issue>\\n          <fpage>1833</fpage>\\n          <lpage>1834</lpage>\\n          <pub-id pub-id-type=\"doi\">10.1016/S0140-6736(11)60834-9</pub-id>\\n          <pub-id pub-id-type=\"pmid\">22118433</pub-id>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR2\">\\n        <label>2.</label>\\n        <element-citation publication-type=\"journal\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Elliot</surname>\\n              <given-names>AJ</given-names>\\n            </name>\\n            <name>\\n              <surname>Morbey</surname>\\n              <given-names>RA</given-names>\\n            </name>\\n            <name>\\n              <surname>Hughes</surname>\\n              <given-names>HE</given-names>\\n            </name>\\n            <name>\\n              <surname>Harcourt</surname>\\n              <given-names>SE</given-names>\\n            </name>\\n            <name>\\n              <surname>Smith</surname>\\n              <given-names>S</given-names>\\n            </name>\\n            <name>\\n              <surname>Loveridge</surname>\\n              <given-names>P</given-names>\\n            </name>\\n            <name>\\n              <surname>Edeghere</surname>\\n              <given-names>O</given-names>\\n            </name>\\n            <name>\\n              <surname>Ibbotson</surname>\\n              <given-names>S</given-names>\\n            </name>\\n            <name>\\n              <surname>McCloskey</surname>\\n              <given-names>B</given-names>\\n            </name>\\n            <name>\\n              <surname>Catchpole</surname>\\n              <given-names>M</given-names>\\n            </name>\\n            <etal/>\\n          </person-group>\\n          <article-title>Syndromic surveillance - a public health legacy of the London 2012 Olympic and Paralympic Games</article-title>\\n          <source>Public Health</source>\\n          <year>2013</year>\\n          <volume>127</volume>\\n          <issue>8</issue>\\n          <fpage>777</fpage>\\n          <lpage>781</lpage>\\n          <pub-id pub-id-type=\"doi\">10.1016/j.puhe.2013.05.007</pub-id>\\n          <pub-id pub-id-type=\"pmid\">23870845</pub-id>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR3\">\\n        <label>3.</label>\\n        <element-citation publication-type=\"journal\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Harcourt</surname>\\n              <given-names>SE</given-names>\\n            </name>\\n            <name>\\n              <surname>Fletcher</surname>\\n              <given-names>J</given-names>\\n            </name>\\n            <name>\\n              <surname>Loveridge</surname>\\n              <given-names>P</given-names>\\n            </name>\\n            <name>\\n              <surname>Bains</surname>\\n              <given-names>A</given-names>\\n            </name>\\n            <name>\\n              <surname>Morbey</surname>\\n              <given-names>R</given-names>\\n            </name>\\n            <name>\\n              <surname>Yeates</surname>\\n              <given-names>A</given-names>\\n            </name>\\n            <name>\\n              <surname>McCloskey</surname>\\n              <given-names>B</given-names>\\n            </name>\\n            <name>\\n              <surname>Smyth</surname>\\n              <given-names>B</given-names>\\n            </name>\\n            <name>\\n              <surname>Ibbotson</surname>\\n              <given-names>S</given-names>\\n            </name>\\n            <name>\\n              <surname>Smith</surname>\\n              <given-names>GE</given-names>\\n            </name>\\n            <etal/>\\n          </person-group>\\n          <article-title>Developing a new syndromic surveillance system for the London 2012 Olympic and Paralympic Games</article-title>\\n          <source>Epidemiol Infect</source>\\n          <year>2012</year>\\n          <volume>140</volume>\\n          <issue>12</issue>\\n          <fpage>2152</fpage>\\n          <lpage>2156</lpage>\\n          <pub-id pub-id-type=\"doi\">10.1017/S0950268812001781</pub-id>\\n          <pub-id pub-id-type=\"pmid\">22892324</pub-id>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR4\">\\n        <label>4.</label>\\n        <element-citation publication-type=\"journal\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Elliot</surname>\\n              <given-names>AJ</given-names>\\n            </name>\\n            <name>\\n              <surname>Hughes</surname>\\n              <given-names>HE</given-names>\\n            </name>\\n            <name>\\n              <surname>Hughes</surname>\\n              <given-names>TC</given-names>\\n            </name>\\n            <name>\\n              <surname>Locker</surname>\\n              <given-names>TE</given-names>\\n            </name>\\n            <name>\\n              <surname>Shannon</surname>\\n              <given-names>T</given-names>\\n            </name>\\n            <name>\\n              <surname>Heyworth</surname>\\n              <given-names>J</given-names>\\n            </name>\\n            <name>\\n              <surname>Wapling</surname>\\n              <given-names>A</given-names>\\n            </name>\\n            <name>\\n              <surname>Catchpole</surname>\\n              <given-names>M</given-names>\\n            </name>\\n            <name>\\n              <surname>Ibbotson</surname>\\n              <given-names>S</given-names>\\n            </name>\\n            <name>\\n              <surname>McCloskey</surname>\\n              <given-names>B</given-names>\\n            </name>\\n            <etal/>\\n          </person-group>\\n          <article-title>Establishing an emergency department syndromic surveillance system to support the London 2012 Olympic and Paralympic Games</article-title>\\n          <source>Emerg Med J</source>\\n          <year>2012</year>\\n          <volume>29</volume>\\n          <issue>12</issue>\\n          <fpage>954</fpage>\\n          <lpage>60</lpage>\\n          <pub-id pub-id-type=\"doi\">10.1136/emermed-2011-200684</pub-id>\\n          <pub-id pub-id-type=\"pmid\">22366039</pub-id>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR5\">\\n        <label>5.</label>\\n        <mixed-citation publication-type=\"other\">Harcourt SE, Morbey RA, Loveridge P, Carrilho L, Baynham D, Povey E, Fox P, Rutter J, Moores P, Tiffen J, et al. Developing and validating a new national remote health advice syndromic surveillance system in England. J Public health. 2016;39(1):184&#x2013;92.</mixed-citation>\\n      </ref>\\n      <ref id=\"CR6\">\\n        <label>6.</label>\\n        <element-citation publication-type=\"book\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Muller</surname>\\n              <given-names>W</given-names>\\n            </name>\\n            <name>\\n              <surname>Schumann</surname>\\n              <given-names>H</given-names>\\n            </name>\\n          </person-group>\\n          <article-title>Visualization for modeling and simulation: visualization methods for time-dependent data - an overview</article-title>\\n          <source>Proceedings of the 35th conference on Winter simulation: driving innovation</source>\\n          <year>2003</year>\\n          <publisher-loc>New Orleans</publisher-loc>\\n          <publisher-name>Winter Simulation Conference</publisher-name>\\n          <fpage>737</fpage>\\n          <lpage>745</lpage>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR7\">\\n        <label>7.</label>\\n        <mixed-citation publication-type=\"other\">Hauenstein L, Wojcik R, Loschen W, Ashar R, Sniegoski C, Tabernero N. Putting it together: the biosurveillance information system. In: Lombardo JS, Buckeridge DL, editors. Disease Surveillance A Public Health Informatics Approach. NJ: John Wiley &amp; Sons Inc; 2007.</mixed-citation>\\n      </ref>\\n      <ref id=\"CR8\">\\n        <label>8.</label>\\n        <element-citation publication-type=\"journal\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Erbas</surname>\\n              <given-names>B</given-names>\\n            </name>\\n            <name>\\n              <surname>Hyndman</surname>\\n              <given-names>R</given-names>\\n            </name>\\n          </person-group>\\n          <article-title>Data visualisation for time series in environmental epidemiology</article-title>\\n          <source>Journal of Epidemiology and Biostats</source>\\n          <year>2001</year>\\n          <volume>6</volume>\\n          <issue>6</issue>\\n          <fpage>433</fpage>\\n          <lpage>443</lpage>\\n          <pub-id pub-id-type=\"doi\">10.1080/135952201317225462</pub-id>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR9\">\\n        <label>9.</label>\\n        <element-citation publication-type=\"journal\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Harcourt</surname>\\n              <given-names>SE</given-names>\\n            </name>\\n            <name>\\n              <surname>Smith</surname>\\n              <given-names>GE</given-names>\\n            </name>\\n            <name>\\n              <surname>Elliot</surname>\\n              <given-names>AJ</given-names>\\n            </name>\\n            <name>\\n              <surname>Pebody</surname>\\n              <given-names>R</given-names>\\n            </name>\\n            <name>\\n              <surname>Charlett</surname>\\n              <given-names>A</given-names>\\n            </name>\\n            <name>\\n              <surname>Ibbotson</surname>\\n              <given-names>S</given-names>\\n            </name>\\n            <name>\\n              <surname>Regan</surname>\\n              <given-names>M</given-names>\\n            </name>\\n            <name>\\n              <surname>Hippisley-Cox</surname>\\n              <given-names>J</given-names>\\n            </name>\\n          </person-group>\\n          <article-title>Use of a large general practice syndromic surveillance system to monitor the progress of the influenza A(H1N1) pandemic 2009 in the UK</article-title>\\n          <source>Epidemiol Infect</source>\\n          <year>2012</year>\\n          <volume>140</volume>\\n          <issue>1</issue>\\n          <fpage>100</fpage>\\n          <lpage>105</lpage>\\n          <pub-id pub-id-type=\"doi\">10.1017/S095026881100046X</pub-id>\\n          <pub-id pub-id-type=\"pmid\">21473803</pub-id>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR10\">\\n        <label>10.</label>\\n        <mixed-citation publication-type=\"other\">Morbey RA, Elliot AJ, Charlett A, Verlander NQ, Andrews N, Smith GE. The application of a novel &#x2018;rising activity, multi-level mixed effects, indicator emphasis&#x2019; (RAMMIE) method for syndromic surveillance in England. Bioinformatics. 2015;31(22):3660&#x2013;5.</mixed-citation>\\n      </ref>\\n      <ref id=\"CR11\">\\n        <label>11.</label>\\n        <element-citation publication-type=\"journal\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Moore</surname>\\n              <given-names>KM</given-names>\\n            </name>\\n            <name>\\n              <surname>Edge</surname>\\n              <given-names>G</given-names>\\n            </name>\\n            <name>\\n              <surname>Kurc</surname>\\n              <given-names>AR</given-names>\\n            </name>\\n          </person-group>\\n          <article-title>Visualization techniques and graphical user interfaces in syndromic surveillance systems. Summary from the Disease Surveillance Workshop, Sept. 11&#x2013;12, 2007; Bangkok, Thailand</article-title>\\n          <source>BMC Proc</source>\\n          <year>2008</year>\\n          <volume>2</volume>\\n          <issue>3</issue>\\n          <fpage>1</fpage>\\n          <lpage>6</lpage>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR12\">\\n        <label>12.</label>\\n        <mixed-citation publication-type=\"other\">Research and Analysis: GP in hours bulletin. <ext-link ext-link-type=\"uri\" xlink:href=\"https://www.gov.uk/government/publications/gp-in-hours-bulletin\">https://www.gov.uk/government/publications/gp-in-hours-bulletin</ext-link>. Accessed 12 May 2017.</mixed-citation>\\n      </ref>\\n      <ref id=\"CR13\">\\n        <label>13.</label>\\n        <element-citation publication-type=\"journal\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Mandl</surname>\\n              <given-names>KD</given-names>\\n            </name>\\n            <name>\\n              <surname>Overhage</surname>\\n              <given-names>JM</given-names>\\n            </name>\\n            <name>\\n              <surname>Wagner</surname>\\n              <given-names>MM</given-names>\\n            </name>\\n            <name>\\n              <surname>Lober</surname>\\n              <given-names>WB</given-names>\\n            </name>\\n            <name>\\n              <surname>Sebastiani</surname>\\n              <given-names>P</given-names>\\n            </name>\\n            <name>\\n              <surname>Mostashari</surname>\\n              <given-names>F</given-names>\\n            </name>\\n            <name>\\n              <surname>Pavlin</surname>\\n              <given-names>JA</given-names>\\n            </name>\\n            <name>\\n              <surname>Gesteland</surname>\\n              <given-names>PH</given-names>\\n            </name>\\n            <name>\\n              <surname>Treadwell</surname>\\n              <given-names>T</given-names>\\n            </name>\\n            <name>\\n              <surname>Koski</surname>\\n              <given-names>E</given-names>\\n            </name>\\n            <etal/>\\n          </person-group>\\n          <article-title>Implementing Syndromic Surveillance: A Practical Guide Informed by the Early Experience</article-title>\\n          <source>J Am Med Inform Assoc</source>\\n          <year>2004</year>\\n          <volume>11</volume>\\n          <issue>2</issue>\\n          <fpage>141</fpage>\\n          <lpage>150</lpage>\\n          <pub-id pub-id-type=\"doi\">10.1197/jamia.M1356</pub-id>\\n          <pub-id pub-id-type=\"pmid\">14633933</pub-id>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR14\">\\n        <label>14.</label>\\n        <element-citation publication-type=\"journal\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Chretien</surname>\\n              <given-names>JP</given-names>\\n            </name>\\n            <name>\\n              <surname>Burkom</surname>\\n              <given-names>HS</given-names>\\n            </name>\\n            <name>\\n              <surname>Sedyaningsih</surname>\\n              <given-names>ER</given-names>\\n            </name>\\n            <name>\\n              <surname>Larasati</surname>\\n              <given-names>RP</given-names>\\n            </name>\\n            <name>\\n              <surname>Lescano</surname>\\n              <given-names>AG</given-names>\\n            </name>\\n            <name>\\n              <surname>Mundaca</surname>\\n              <given-names>CC</given-names>\\n            </name>\\n            <name>\\n              <surname>Blazes</surname>\\n              <given-names>DL</given-names>\\n            </name>\\n            <name>\\n              <surname>Munayco</surname>\\n              <given-names>CV</given-names>\\n            </name>\\n            <name>\\n              <surname>Coberly</surname>\\n              <given-names>JS</given-names>\\n            </name>\\n            <name>\\n              <surname>Ashar</surname>\\n              <given-names>RJ</given-names>\\n            </name>\\n            <etal/>\\n          </person-group>\\n          <article-title>Syndromic surveillance: adapting innovations to developing settings</article-title>\\n          <source>PLoS Med</source>\\n          <year>2008</year>\\n          <volume>5</volume>\\n          <issue>3</issue>\\n          <pub-id pub-id-type=\"doi\">10.1371/journal.pmed.0050072</pub-id>\\n          <pub-id pub-id-type=\"pmid\">18366250</pub-id>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR15\">\\n        <label>15.</label>\\n        <element-citation publication-type=\"journal\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Riley</surname>\\n              <given-names>P</given-names>\\n            </name>\\n            <name>\\n              <surname>Cost</surname>\\n              <given-names>AA</given-names>\\n            </name>\\n            <name>\\n              <surname>Riley</surname>\\n              <given-names>S</given-names>\\n            </name>\\n          </person-group>\\n          <article-title>Intra-Weekly Variations of Influenza-Like Illness in Military Populations</article-title>\\n          <source>Mil Med</source>\\n          <year>2016</year>\\n          <volume>181</volume>\\n          <issue>4</issue>\\n          <fpage>364</fpage>\\n          <lpage>368</lpage>\\n          <pub-id pub-id-type=\"doi\">10.7205/MILMED-D-15-00226</pub-id>\\n          <pub-id pub-id-type=\"pmid\">27046183</pub-id>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR16\">\\n        <label>16.</label>\\n        <element-citation publication-type=\"journal\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Fleming</surname>\\n              <given-names>DM</given-names>\\n            </name>\\n            <name>\\n              <surname>Elliot</surname>\\n              <given-names>AJ</given-names>\\n            </name>\\n          </person-group>\\n          <article-title>Lessons from 40 years&#x2019; surveillance of influenza in England and Wales</article-title>\\n          <source>Epidemiology &amp; Infection</source>\\n          <year>2008</year>\\n          <volume>136</volume>\\n          <issue>07</issue>\\n          <fpage>866</fpage>\\n          <lpage>875</lpage>\\n          <pub-id pub-id-type=\"doi\">10.1017/S0950268807009910</pub-id>\\n          <pub-id pub-id-type=\"pmid\">18047750</pub-id>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR17\">\\n        <label>17.</label>\\n        <mixed-citation publication-type=\"other\">Wong W-K, Moore AW. Classical Time-Series Methods for Biosurveillance. In: Wagner MM, Moore AW, Aryel RM, editors. Handbook of Biosurveillance. MA: Elsevier Academic Press; 2006.</mixed-citation>\\n      </ref>\\n      <ref id=\"CR18\">\\n        <label>18.</label>\\n        <element-citation publication-type=\"journal\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Bollaerts</surname>\\n              <given-names>K</given-names>\\n            </name>\\n            <name>\\n              <surname>Antoine</surname>\\n              <given-names>J</given-names>\\n            </name>\\n            <name>\\n              <surname>Robesyn</surname>\\n              <given-names>E</given-names>\\n            </name>\\n            <name>\\n              <surname>Van Proeyen</surname>\\n              <given-names>L</given-names>\\n            </name>\\n            <name>\\n              <surname>Vomberg</surname>\\n              <given-names>J</given-names>\\n            </name>\\n            <name>\\n              <surname>Feys</surname>\\n              <given-names>E</given-names>\\n            </name>\\n            <name>\\n              <surname>De Decker</surname>\\n              <given-names>E</given-names>\\n            </name>\\n            <name>\\n              <surname>Catry</surname>\\n              <given-names>B</given-names>\\n            </name>\\n          </person-group>\\n          <article-title>Timeliness of syndromic influenza surveillance through work and school absenteeism</article-title>\\n          <source>Archives of Public Health</source>\\n          <year>2010</year>\\n          <volume>68</volume>\\n          <issue>3</issue>\\n          <fpage>115</fpage>\\n          <lpage>120</lpage>\\n          <pub-id pub-id-type=\"doi\">10.1186/0778-7367-68-3-115</pub-id>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR19\">\\n        <label>19.</label>\\n        <element-citation publication-type=\"journal\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Burkom</surname>\\n              <given-names>HS</given-names>\\n            </name>\\n            <name>\\n              <surname>Murphy</surname>\\n              <given-names>SP</given-names>\\n            </name>\\n            <name>\\n              <surname>Shmueli</surname>\\n              <given-names>G</given-names>\\n            </name>\\n          </person-group>\\n          <article-title>Automated time series forecasting for biosurveillance</article-title>\\n          <source>Stat Med</source>\\n          <year>2007</year>\\n          <volume>26</volume>\\n          <issue>22</issue>\\n          <fpage>4202</fpage>\\n          <lpage>4218</lpage>\\n          <pub-id pub-id-type=\"doi\">10.1002/sim.2835</pub-id>\\n          <pub-id pub-id-type=\"pmid\">17335120</pub-id>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR20\">\\n        <label>20.</label>\\n        <element-citation publication-type=\"book\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Forsberg</surname>\\n              <given-names>L</given-names>\\n            </name>\\n            <name>\\n              <surname>Jeffery</surname>\\n              <given-names>C</given-names>\\n            </name>\\n            <name>\\n              <surname>Ozonoff</surname>\\n              <given-names>A</given-names>\\n            </name>\\n            <name>\\n              <surname>Pagano</surname>\\n              <given-names>M</given-names>\\n            </name>\\n          </person-group>\\n          <person-group person-group-type=\"editor\">\\n            <name>\\n              <surname>Wilson</surname>\\n              <given-names>A</given-names>\\n            </name>\\n            <name>\\n              <surname>Wilson</surname>\\n              <given-names>G</given-names>\\n            </name>\\n            <name>\\n              <surname>Olwell</surname>\\n              <given-names>D</given-names>\\n            </name>\\n          </person-group>\\n          <article-title>A Spatiotemporal Analysis of Syndromic Data for Biosurveillance</article-title>\\n          <source>Statistical Methods in Counterterrorism</source>\\n          <year>2006</year>\\n          <publisher-loc>New York</publisher-loc>\\n          <publisher-name>Springer</publisher-name>\\n          <fpage>173</fpage>\\n          <lpage>191</lpage>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR21\">\\n        <label>21.</label>\\n        <element-citation publication-type=\"journal\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Shmueli</surname>\\n              <given-names>G</given-names>\\n            </name>\\n            <name>\\n              <surname>Burkom</surname>\\n              <given-names>HS</given-names>\\n            </name>\\n          </person-group>\\n          <article-title>Statistical challenges in modern biosurveillance</article-title>\\n          <source>Technometrics</source>\\n          <year>2006</year>\\n          <volume>52</volume>\\n          <issue>1</issue>\\n          <fpage>39</fpage>\\n          <lpage>51</lpage>\\n          <pub-id pub-id-type=\"doi\">10.1198/TECH.2010.06134</pub-id>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR22\">\\n        <label>22.</label>\\n        <mixed-citation publication-type=\"other\">Wijk JJV, Selow ERV. Cluster and calendar based visualization of time series data. In: Information Visualization, 1999 (Info Vis &#x2018;99) Proceedings 1999 IEEE Symposium; 1999. p. 4&#x2013;9, 140.</mixed-citation>\\n      </ref>\\n      <ref id=\"CR23\">\\n        <label>23.</label>\\n        <mixed-citation publication-type=\"other\">Maciejewski R, Rudolph S, Grannis SJ, Ebert DS. The day-of-the-week effect: a study across the Indiana Public Health Emergency Surveillance System. International Society for Disease Surveillance Annual Conference Advances in Disease Surveillance 2008, 5(44).</mixed-citation>\\n      </ref>\\n      <ref id=\"CR24\">\\n        <label>24.</label>\\n        <mixed-citation publication-type=\"other\">Engineering Statistics Handbook: e-Handbook of Statistical Methods. <ext-link ext-link-type=\"uri\" xlink:href=\"http://www.itl.nist.gov/div898/handbook\">http://www.itl.nist.gov/div898/handbook/</ext-link>. Accessed 12 May 2017.</mixed-citation>\\n      </ref>\\n      <ref id=\"CR25\">\\n        <label>25.</label>\\n        <element-citation publication-type=\"journal\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Shmueli</surname>\\n              <given-names>G</given-names>\\n            </name>\\n            <name>\\n              <surname>Burkom</surname>\\n              <given-names>H</given-names>\\n            </name>\\n          </person-group>\\n          <article-title>Statistical Challenges Facing Early Outbreak Detection in Biosurveillance</article-title>\\n          <source>Technometrics</source>\\n          <year>2010</year>\\n          <volume>52</volume>\\n          <issue>1</issue>\\n          <fpage>39</fpage>\\n          <lpage>51</lpage>\\n          <pub-id pub-id-type=\"doi\">10.1198/TECH.2010.06134</pub-id>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR26\">\\n        <label>26.</label>\\n        <mixed-citation publication-type=\"other\">Lotze T, Shmueli G, Murphy S, Burkom H. A wavelet-based anomaly detector for early detection of disease outbreaks. In: Workshop on Machine Learning Algorithms for Surveillance and Event Detection, 23rd Intl Conference on Machine Learning; 2006.</mixed-citation>\\n      </ref>\\n      <ref id=\"CR27\">\\n        <label>27.</label>\\n        <mixed-citation publication-type=\"other\">Siegrist D, McClellan G, Campbell M, Foster V, Burkom H, Hogan W, Cheng K, Buckeridge D, Pavlin J, Kress A. Evaluation of algorithms for outbreak detection using clinical data from five us cities. VA: Technical report, DARPA Bio-ALIRT Program; 2004.</mixed-citation>\\n      </ref>\\n      <ref id=\"CR28\">\\n        <label>28.</label>\\n        <element-citation publication-type=\"journal\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Batal</surname>\\n              <given-names>H</given-names>\\n            </name>\\n            <name>\\n              <surname>Tench</surname>\\n              <given-names>J</given-names>\\n            </name>\\n            <name>\\n              <surname>McMillan</surname>\\n              <given-names>S</given-names>\\n            </name>\\n            <name>\\n              <surname>Adams</surname>\\n              <given-names>J</given-names>\\n            </name>\\n            <name>\\n              <surname>Mehler</surname>\\n              <given-names>PS</given-names>\\n            </name>\\n          </person-group>\\n          <article-title>Predicting Patient Visits to an Urgent Care Clinic Using Calendar Variables</article-title>\\n          <source>Acad Emerg Med</source>\\n          <year>2001</year>\\n          <volume>8</volume>\\n          <issue>1</issue>\\n          <fpage>48</fpage>\\n          <lpage>53</lpage>\\n          <pub-id pub-id-type=\"doi\">10.1111/j.1553-2712.2001.tb00550.x</pub-id>\\n          <pub-id pub-id-type=\"pmid\">11136148</pub-id>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR29\">\\n        <label>29.</label>\\n        <element-citation publication-type=\"journal\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Holleman</surname>\\n              <given-names>DR</given-names>\\n            </name>\\n            <name>\\n              <surname>Bowling</surname>\\n              <given-names>RL</given-names>\\n            </name>\\n            <name>\\n              <surname>Gathy</surname>\\n              <given-names>C</given-names>\\n            </name>\\n          </person-group>\\n          <article-title>Predicting daily visits to a waik-in clinic and emergency department using calendar and weather data</article-title>\\n          <source>J Gen Intern Med</source>\\n          <year>1996</year>\\n          <volume>11</volume>\\n          <issue>4</issue>\\n          <fpage>237</fpage>\\n          <lpage>239</lpage>\\n          <pub-id pub-id-type=\"doi\">10.1007/BF02642481</pub-id>\\n          <pub-id pub-id-type=\"pmid\">8744882</pub-id>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR30\">\\n        <label>30.</label>\\n        <element-citation publication-type=\"journal\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Gamagedara</surname>\\n              <given-names>N</given-names>\\n            </name>\\n            <name>\\n              <surname>Hocking</surname>\\n              <given-names>JS</given-names>\\n            </name>\\n            <name>\\n              <surname>Law</surname>\\n              <given-names>M</given-names>\\n            </name>\\n            <name>\\n              <surname>Fehler</surname>\\n              <given-names>G</given-names>\\n            </name>\\n            <name>\\n              <surname>Chen</surname>\\n              <given-names>MY</given-names>\\n            </name>\\n            <name>\\n              <surname>Bradshaw</surname>\\n              <given-names>CS</given-names>\\n            </name>\\n            <name>\\n              <surname>Fairley</surname>\\n              <given-names>CK</given-names>\\n            </name>\\n          </person-group>\\n          <article-title>What are seasonal and meteorological factors are associated with the number of attendees at a sexual health service? An observational study between 2002&#x2013;2012</article-title>\\n          <source>Sex Transm Infect</source>\\n          <year>2014</year>\\n          <volume>90</volume>\\n          <issue>8</issue>\\n          <fpage>635</fpage>\\n          <lpage>640</lpage>\\n          <pub-id pub-id-type=\"doi\">10.1136/sextrans-2013-051391</pub-id>\\n          <pub-id pub-id-type=\"pmid\">25053658</pub-id>\\n        </element-citation>\\n      </ref>\\n      <ref id=\"CR31\">\\n        <label>31.</label>\\n        <element-citation publication-type=\"journal\">\\n          <person-group person-group-type=\"author\">\\n            <name>\\n              <surname>Elliot</surname>\\n              <given-names>AJ</given-names>\\n            </name>\\n            <name>\\n              <surname>Kara</surname>\\n              <given-names>EO</given-names>\\n            </name>\\n            <name>\\n              <surname>Loveridge</surname>\\n              <given-names>P</given-names>\\n            </name>\\n            <name>\\n              <surname>Bawa</surname>\\n              <given-names>Z</given-names>\\n            </name>\\n            <name>\\n              <surname>Morbey</surname>\\n              <given-names>RA</given-names>\\n            </name>\\n            <name>\\n              <surname>Moth</surname>\\n              <given-names>M</given-names>\\n            </name>\\n            <name>\\n              <surname>Large</surname>\\n              <given-names>S</given-names>\\n            </name>\\n            <name>\\n              <surname>Smith</surname>\\n              <given-names>GE</given-names>\\n            </name>\\n          </person-group>\\n          <article-title>Internet-based remote health self-checker symptom data as an adjuvant to a national syndromic surveillance system</article-title>\\n          <source>Epidemiology &amp; Infection</source>\\n          <year>2015</year>\\n          <volume>143</volume>\\n          <issue>16</issue>\\n          <fpage>3416</fpage>\\n          <lpage>3422</lpage>\\n          <pub-id pub-id-type=\"doi\">10.1017/S0950268815000503</pub-id>\\n          <pub-id pub-id-type=\"pmid\">25858297</pub-id>\\n        </element-citation>\\n      </ref>\\n    </ref-list>\\n  </back>\\n</article>\\n</pmc-articleset>\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc =  open('pmc_result.xml').read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pmid', 'pmc', 'publisher-id', 'doi']\n"
     ]
    }
   ],
   "source": [
    "doc.find('article')\n",
    "import lxml.html\n",
    "xml = lxml.html.fromstring(doc)\n",
    "article = xml.xpath(\"//article\")[0]\n",
    "[elem for elem in dir(article) if \"__\" not in elem]\n",
    "[elem.text_content() for elem in article.xpath('//article-id')]\n",
    "thing = [elem for elem in article.xpath(\"//article-id/@pub-id-type\")]\n",
    "print(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NCBIResults parses the output of what's pulled from the API and outputs a dataframe\n",
    "class NCBIResults:\n",
    "    def __init__(self, db):\n",
    "        self.db = db\n",
    "        if db == \"pubmed\":\n",
    "            self.__class__ = pubmedFetch\n",
    "        elif db == 'pmc':\n",
    "            self.__class__ = pmcFetch\n",
    "\n",
    "class pubmedFetch(NCBIResults):\n",
    "      def parseArticle(self, soup):\n",
    "            ArticleList = soup.find_all('PubmedArticle')\n",
    "            articleList = []\n",
    "\n",
    "            for article in ArticleList:\n",
    "                ssList = []\n",
    "\n",
    "                 ####### title ########\n",
    "                title = article.find('ArticleTitle').text\n",
    "\n",
    "                ####### pmid #########\n",
    "                associatedId = article.find('PMID').text\n",
    "\n",
    "                ####### journal ########\n",
    "                journal = article.find('Title').text   \n",
    "\n",
    "                ####### meshterms ##########\n",
    "\n",
    "                #each meshterm will have its word and possibly some qualifiernames\n",
    "                meshList = []\n",
    "\n",
    "                try:\n",
    "                    meshTermList = article.find_all('MeshHeading')\n",
    "                    for term in meshTermList:\n",
    "                        descriptorTerm = term.find('DescriptorName').text\n",
    "                        qualifierList = []\n",
    "                        try:\n",
    "                            qualifierNameList = term.find_all('QualifierName')\n",
    "                            for qual in qualifierNameList:\n",
    "                                thisQual = qual.text\n",
    "                                qualifierList.append(thisQual)\n",
    "                        except: \n",
    "                            qualifierList = None\n",
    "\n",
    "                        mtDict = {'term': descriptorTerm, 'qualList': qualifierList}\n",
    "                        meshList.append(mtDict)\n",
    "                except:\n",
    "                    meshList = None\n",
    "\n",
    "                ######## article date ###########\n",
    "\n",
    "                if article.find('ArticleDate'):\n",
    "                    year = article.find('DateCreated').find('Year').text\n",
    "                    month = article.find('DateCreated').find('Month').text\n",
    "                    day = article.find('DateCreated').find('Day').text\n",
    "                    dateDict = {'month':month,'year':year,'day':day}\n",
    "                    fulldate = '{0}/{1}/{2}'.format(month,day,year)\n",
    "                if not article.find('ArticleDate'):\n",
    "                    year = article.find('DateCreated').find('Year').text\n",
    "                    month = article.find('DateCreated').find('Month').text\n",
    "                    day = article.find('DateCreated').find('Day').text\n",
    "                    dateDict = {'month':month,'year':year,'day':day}\n",
    "                    fulldate = '{0}/{1}/{2}'.format(month,day,year)\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "                ######### pubtype ##########\n",
    "#                 pubTypeVal = \"\"\n",
    "#                 try:\n",
    "#                     pubTypes = article.find_all('PublicationType')\n",
    "#                     for pub in pubTypes:\n",
    "#                         try:\n",
    "#                             pubTypeVal = pub.text\n",
    "#                         except:\n",
    "#                             pubTypeVal = None   \n",
    "#                 except:\n",
    "#                     pubTypeVal = None\n",
    "\n",
    "                pubTypeVal = \"\"\n",
    "                try:\n",
    "                    pubTypes = article.find('PublicationType')\n",
    "                    pubTypeVal = pubTypes.text\n",
    "                except:\n",
    "                    pubTypeVal = None\n",
    "                    \n",
    "                    \n",
    "                ######### abstract ##########\n",
    "\n",
    "                abstractList = []\n",
    "                try:\n",
    "                    abstractText = article.find('Abstract')\n",
    "                    sections = abstractText.find_all('AbstractText')\n",
    "                    if sections[0].get('Label'):\n",
    "                        #broken up by nlm category\n",
    "                        for sec in sections:\n",
    "                            abstractDict = {}\n",
    "                            abstractDict['NlmCategory'] = sec.get('NlmCategory')\n",
    "                            abstractDict['Label'] = sec.get('Label')\n",
    "                            abstractDict['text'] = sec.text\n",
    "                            abstractList.append(abstractDict)\n",
    "                    if not sections[0].get('Label'):\n",
    "                        #comes as whole chunk\n",
    "                        abstractDict = {}\n",
    "                        abstractFull = abstractText.find('AbstractText').text\n",
    "                        abstractDict['wholetext'] = abstractFull\n",
    "                        abstractList.append(abstractDict)\n",
    "                except:\n",
    "                    #this means there is no abstract at all\n",
    "                    abstractList = None\n",
    "\n",
    "                ############ authors ###############\n",
    "\n",
    "                #each article will have a list of authors. Each author is represented by a dictionary (key values: fname, lname, affliation)\n",
    "                authList = []\n",
    "                #some articles don't have an author\n",
    "                try:          \n",
    "                    authorList = article.find('AuthorList')\n",
    "                    for author in authorList:\n",
    "                        try:\n",
    "                            affiliation = author.find('CollectiveName').text\n",
    "                            lname = None\n",
    "                            fname = None\n",
    "                        except:\n",
    "                            try:\n",
    "                                lname = author.find('LastName').text\n",
    "                            except:\n",
    "                                lname = None\n",
    "                            try:\n",
    "                                fname = author.find('ForeName').text\n",
    "                            except:\n",
    "                                fname = None\n",
    "                            try:\n",
    "                                affiliation = author.find('Affiliation').text\n",
    "                            except:\n",
    "                                affiliation = None\n",
    "                            authDict = {'lname':lname,'fname':fname, 'affl':affiliation}\n",
    "                            authList.append(authDict)\n",
    "\n",
    "                except:\n",
    "                    authList = None\n",
    "\n",
    "                ######### doi ##########\n",
    "                doi = None\n",
    "\n",
    "                try:\n",
    "                    doiList = article.find_all('ArticleId')\n",
    "\n",
    "                    for doiM in doiList:\n",
    "                        if doiM.get('IdType') == 'doi':\n",
    "                            doi = doiM.text\n",
    "                except:\n",
    "\n",
    "                    try:\n",
    "                        doiList = article.find_all('ELocationID')\n",
    "                        for doiM in doiList:\n",
    "                            if doiM.get('IdType') == 'doi':\n",
    "                                doi = doiM.text\n",
    "                    except:\n",
    "                        doi = None\n",
    "\n",
    "\n",
    "                d = {\n",
    "                        'title': title,\n",
    "                        'associatedId' : associatedId,\n",
    "                        'author': authList,    \n",
    "                        'journal' : journal,\n",
    "                        'pubtype': pubTypeVal,\n",
    "                        'publishdate': fulldate,\n",
    "                        'publishdatefull': dateDict,\n",
    "                        'meshterms': meshList,\n",
    "                        'abstract': abstractList,\n",
    "                        'optionalId01' : doi,\n",
    "                        'optionalId02': None\n",
    "                 }\n",
    "\n",
    "                articleList.append(d)\n",
    "            return pd.DataFrame(articleList)\n",
    "        \n",
    "class pmcFetch(NCBIResults):\n",
    "      def parseArticle(self, soup):\n",
    "\n",
    "        ArticleList = soup.find_all('article')\n",
    "        articleList = []\n",
    "        for article in ArticleList:\n",
    "\n",
    "            ####### title ########\n",
    "            title = article.find('article-title').text.replace('\\n', ' ')\n",
    "\n",
    "\n",
    "            ####### journal ########\n",
    "            journal = article.find('journal-title').text \n",
    "\n",
    "            ####### pmc id and doi id #########\n",
    "\n",
    "            associatedId = None\n",
    "            doi = None\n",
    "            pmid = None\n",
    "            litIdList=article.find_all('article-id')\n",
    "\n",
    "            for lit in litIdList:\n",
    "                idType = lit.get('pub-id-type')\n",
    "                try:\n",
    "                    if idType == 'pmc':\n",
    "                        associatedId = lit.text\n",
    "                except:\n",
    "                    associatedId = None\n",
    "                try:\n",
    "                    if idType == 'doi':\n",
    "                        doi = lit.text\n",
    "                except:\n",
    "                    doi = None\n",
    "                try:\n",
    "                    if idType == \"pmid\":\n",
    "                        pmid = lit.text\n",
    "                except:\n",
    "                    pmid = None\n",
    "\n",
    "            ######## article date ###########\n",
    "            dateListInt = []\n",
    "            dateDictList = []\n",
    "            allDates = article.find_all('pub-date')\n",
    "            for dates in allDates:\n",
    "                try:    \n",
    "                    month = dates.find('month').text\n",
    "                except:\n",
    "                    month = None\n",
    "                try:\n",
    "                    year = dates.find('year').text\n",
    "                except:\n",
    "                    year = None\n",
    "                try:\n",
    "                    day = dates.find('day').text\n",
    "                except:\n",
    "                    day = None\n",
    "                dateDict = {'month':month, 'year':year, 'day':day}\n",
    "                dateDictList.append(dateDict)\n",
    "                fulldatesAll = '{0}/{1}/{2}'.format(month,day,year)\n",
    "                dateListInt.append(fulldatesAll)\n",
    "\n",
    "\n",
    "            dateValList = [num for num in dateListInt if 'None' not in num]\n",
    "            if dateValList == []:\n",
    "            #     dateValList = [num for num in dateListInt if 'None' in num]\n",
    "                dateVal = None\n",
    "\n",
    "            try:\n",
    "                if isinstance(dateValList[0], str):\n",
    "                    dateVal = dateValList[0]\n",
    "                if isinstance(dateValList, str):\n",
    "                    dateVal = dateValList\n",
    "            except:\n",
    "                dateVal = None\n",
    "\n",
    "\n",
    "            dateDictValList  = [d for d in dateDictList if None not in d.values()]\n",
    "            if not dateDictValList == []:\n",
    "                ddList = dateDictValList\n",
    "            if dateDictValList == []:\n",
    "                ddList  = [d for d in dateDictList if None in d.values()]\n",
    "\n",
    "            try:\n",
    "                if isinstance(ddList[0],dict):\n",
    "                    dateDictVal = ddList[0]\n",
    "                if isinstance(ddList,dict):\n",
    "                    dateDictVal = ddList\n",
    "            except:\n",
    "                dateDictVal = None\n",
    "\n",
    "\n",
    "            ############ authors ###############     \n",
    "            authList = []\n",
    "            #to get the authors names\n",
    "            try:\n",
    "                contribList = article.find('contrib-group').find_all('name')\n",
    "                for author in contribList:\n",
    "                    try:\n",
    "                        lname = author.find('surname').text\n",
    "                    except:\n",
    "                        lname = None\n",
    "                    try:\n",
    "                        fname = author.find('given-names').text\n",
    "                    except:\n",
    "                         fname = None     \n",
    "                    authDict = {'lname':lname,'fname':fname, 'affl':None}\n",
    "                    authList.append(authDict)\n",
    "            except:\n",
    "                authList = None\n",
    "\n",
    "\n",
    "            ###### meshterms ##########\n",
    "\n",
    "            #each meshterm will have its word and possibly some qualifiernames\n",
    "            meshList = []\n",
    "\n",
    "            try:\n",
    "                meshTermList = article.find('kwd-group')\n",
    "                wordList = meshTermList.find_all('kwd')\n",
    "                for term in wordList:\n",
    "                    descriptorTerm = term.text\n",
    "                    mtDict = {'term': descriptorTerm, 'qualifiernames': None}\n",
    "                    meshList.append(mtDict)\n",
    "            except:\n",
    "                meshTermList = None\n",
    "            \n",
    "            ######### publication type ##########\n",
    "            pubTypeVal = \"\"\n",
    "            try:\n",
    "                pubTypes = article.find_all('subj-group')\n",
    "                for pub in pubTypes:\n",
    "                    try:\n",
    "                        pubTypeVal = pub.find('subject').text\n",
    "                    except:\n",
    "                        pubTypeVal = None\n",
    "            except:\n",
    "                pubTypeVal = None\n",
    "            \n",
    "            ######### abstract ##########\n",
    "\n",
    "            abstractList = []\n",
    "            if article.find('abstract'):\n",
    "                abstractText = article.find('abstract')\n",
    "            if not article.find('abstract'):\n",
    "                abstractText = article.find('body')\n",
    "\n",
    "            try:\n",
    "                sections = abstractText.find_all('sec')\n",
    "                for sec in sections:\n",
    "                    abstractDict = {}\n",
    "                    abstractDict['NlmCategory'] = None\n",
    "                    abstractDict['Label'] = sec.find('title').text.replace('\\n', ' ')    \n",
    "                    abstractDict['text'] = sec.find('p').text.replace('\\n', ' ')    \n",
    "                    abstractList.append(abstractDict)\n",
    "            except:\n",
    "                abstractList = []\n",
    "                \n",
    "            if abstractList == []:\n",
    "                try:\n",
    "                    pSections = abstractText.find_all('p')\n",
    "                    pFull = ''\n",
    "                    for p in pSections:\n",
    "                        abstractDict = {}\n",
    "                        pFull += p.text\n",
    "                    abstractDict['wholetext'] = pFull\n",
    "                    abstractList.append(abstractDict)\n",
    "                except:\n",
    "                    abstractList = []\n",
    "\n",
    "            d = {\n",
    "                        'title': title,\n",
    "                        'associatedId' : associatedId,\n",
    "                        'author': authList,    \n",
    "                        'journal' : journal,\n",
    "                        'pubtype': pubTypeVal,\n",
    "                        'publishdate': dateVal,\n",
    "                        'publishdatefull': dateDictVal,\n",
    "                        'meshterms': meshList,\n",
    "                        'abstract': abstractList,\n",
    "                        'optionalId01' : doi,\n",
    "                        'optionalId02': pmid\n",
    "                     }\n",
    "\n",
    "            articleList.append(d)\n",
    "        return pd.DataFrame(articleList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ParseAll iterates through the list of soups, parses and compresses the outputs into one into dataframe\n",
    "def ParseAll(db,soup):\n",
    "    textReturns = NCBIResults(db)\n",
    "    dfText = []\n",
    "    for soupElt in soup:\n",
    "        dfTextInst = textReturns.parseArticle(soupElt)\n",
    "        dfText.append(dfTextInst)\n",
    "        dfFull = pd.concat(dfText,ignore_index=True)\n",
    "    return(dfFull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PullQuery</th>\n",
       "      <th>PullSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(syndromic+surveillance AND emergency+department) AND west+nile</td>\n",
       "      <td>PMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>syndromic+surveillance AND emergency+department+visits</td>\n",
       "      <td>PMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>syndromic+surveillance AND emergency+department[TI]</td>\n",
       "      <td>PMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>syndromic+surveillance AND emergency+department</td>\n",
       "      <td>PMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>syndromic+surveillance[TI]</td>\n",
       "      <td>PMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>syndromic+surveillance AND (emergency+department OR ED)</td>\n",
       "      <td>PMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>syndromic+surveillance AND (emergency+department OR emergency+room)</td>\n",
       "      <td>PMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Online J Public Health Inform[TA] AND syndromic+surveillance[ALL]</td>\n",
       "      <td>PMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Online J Public Health Inform[TA] AND syndromic+surveillance AND (emergency+department OR ED)[ALL]</td>\n",
       "      <td>PMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Online J Public Health Inform AND syndromic+surveillance[TI]</td>\n",
       "      <td>PMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>syndromic+surveillance AND (emergency+department OR ED)</td>\n",
       "      <td>PUBMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>syndromic+surveillance AND (emergency+department OR emergency+room)</td>\n",
       "      <td>PUBMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Online J Public Health Inform[TA] AND syndromic+surveillance AND (emergency+department OR ED)[ALL]</td>\n",
       "      <td>PUBMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>syndromic+surveillance AND emergency+department</td>\n",
       "      <td>PUBMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>syndromic+surveillance AND emergency+department+visits</td>\n",
       "      <td>PUBMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Online J Public Health Inform[TA] AND syndromic+surveillance[ALL]</td>\n",
       "      <td>PUBMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>syndromic+surveillance[TI]</td>\n",
       "      <td>PUBMED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             PullQuery  \\\n",
       "0                                      (syndromic+surveillance AND emergency+department) AND west+nile   \n",
       "13                                              syndromic+surveillance AND emergency+department+visits   \n",
       "12                                                 syndromic+surveillance AND emergency+department[TI]   \n",
       "10                                                     syndromic+surveillance AND emergency+department   \n",
       "15                                                                          syndromic+surveillance[TI]   \n",
       "6                                              syndromic+surveillance AND (emergency+department OR ED)   \n",
       "8                                  syndromic+surveillance AND (emergency+department OR emergency+room)   \n",
       "4                                    Online J Public Health Inform[TA] AND syndromic+surveillance[ALL]   \n",
       "2   Online J Public Health Inform[TA] AND syndromic+surveillance AND (emergency+department OR ED)[ALL]   \n",
       "1                                         Online J Public Health Inform AND syndromic+surveillance[TI]   \n",
       "7                                              syndromic+surveillance AND (emergency+department OR ED)   \n",
       "9                                  syndromic+surveillance AND (emergency+department OR emergency+room)   \n",
       "3   Online J Public Health Inform[TA] AND syndromic+surveillance AND (emergency+department OR ED)[ALL]   \n",
       "11                                                     syndromic+surveillance AND emergency+department   \n",
       "14                                              syndromic+surveillance AND emergency+department+visits   \n",
       "5                                    Online J Public Health Inform[TA] AND syndromic+surveillance[ALL]   \n",
       "16                                                                          syndromic+surveillance[TI]   \n",
       "\n",
       "   PullSource  \n",
       "0         PMC  \n",
       "13        PMC  \n",
       "12        PMC  \n",
       "10        PMC  \n",
       "15        PMC  \n",
       "6         PMC  \n",
       "8         PMC  \n",
       "4         PMC  \n",
       "2         PMC  \n",
       "1         PMC  \n",
       "7      PUBMED  \n",
       "9      PUBMED  \n",
       "3      PUBMED  \n",
       "11     PUBMED  \n",
       "14     PUBMED  \n",
       "5      PUBMED  \n",
       "16     PUBMED  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query db to find existing searches that were done and create unique ones\n",
    "dbName = 'J:/ssUseCases/Database6.accdb'\n",
    "connStr = 'DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=%s;' % dbName\n",
    "cnxn = pyodbc.connect(connStr)\n",
    "cur = cnxn.cursor()\n",
    "query = \"Select distinct PullQuery,PullSource from DataPull_ID\"\n",
    "pullDf = pd.read_sql_query(query,cnxn)\n",
    "pd.set_option('display.max_colwidth',100)\n",
    "pullDf.sort_values(by = 'PullSource')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "email = r's.rand525@gmail.com'\n",
    "# journalTerm = 'Online J Public Health Inform'\n",
    "# keyTerm = r'syndromic+surveillance AND emergency+department+visits' H\n",
    "# keyTerm = r'(syndromic+surveillance AND emergency+department) AND west+nile' \n",
    "# keyTerm = r'syndromic+surveillance AND emergency+department'  H\n",
    "# keyTerm = r'syndromic+surveillance AND (emergency+department OR ED)'  \n",
    "# keyTerm = r'syndromic+surveillance AND (emergency+department OR emergency+room)' H\n",
    "# keyTerm = 'syndromic+surveillance'\n",
    "#to make a title search\n",
    "journalTerm = ''\n",
    "keyTerm = 'syndromic+surveillance[TIAB]'\n",
    "# keyTerm = r'syndromic+surveillance AND emergency+department[TI]'\n",
    "db = 'pubmed'\n",
    "useTags = 'No'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate concatenated search term and idList\n",
    "pmParamObj = searchParams(email, db)\n",
    "pmSearchTerm = pmParamObj.get_term(journalTerm,keyTerm,useTags)\n",
    "pmCount = pmParamObj.get_count(term = pmSearchTerm)\n",
    "pmSearchObj = NCBISearch(email)\n",
    "idList = pmSearchObj.pub_search(term = pmSearchTerm, recordCount=pmCount,chunksize=50000, db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make soup for parsing\n",
    "soup = pmSearchObj.pub_fetch(db = db, idList = idList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse soup into dataframe\n",
    "dfFull = ParseAll(db,soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>associatedId</th>\n",
       "      <th>author</th>\n",
       "      <th>journal</th>\n",
       "      <th>meshterms</th>\n",
       "      <th>optionalId01</th>\n",
       "      <th>optionalId02</th>\n",
       "      <th>publishdate</th>\n",
       "      <th>publishdatefull</th>\n",
       "      <th>pubtype</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>29057228</td>\n",
       "      <td>[{'lname': None, 'fname': None, 'affl': None}, {'lname': 'Barrett', 'fname': 'Damien', 'affl': '...</td>\n",
       "      <td>Frontiers in veterinary science</td>\n",
       "      <td>[]</td>\n",
       "      <td>10.3389/fvets.2017.00150</td>\n",
       "      <td>None</td>\n",
       "      <td>10/23/2017</td>\n",
       "      <td>{'month': '10', 'year': '2017', 'day': '23'}</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>The Potential for Big Data in Animal Disease Surveillance in Ireland.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'wholetext': 'During winter 2014-15, England experienced severe strains on acute health servic...</td>\n",
       "      <td>29048277</td>\n",
       "      <td>[{'lname': None, 'fname': None, 'affl': None}, {'lname': 'Smith', 'fname': 'Sue', 'affl': None},...</td>\n",
       "      <td>Emerging infectious diseases</td>\n",
       "      <td>[]</td>\n",
       "      <td>10.3201/eid2311.161632</td>\n",
       "      <td>None</td>\n",
       "      <td>10/19/2017</td>\n",
       "      <td>{'month': '10', 'year': '2017', 'day': '19'}</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Retrospective Observational Study of Atypical Winter Respiratory Illness Season Using Real-Time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'wholetext': 'The eradication of viral haemorrhagic septicaemia virus (VHSV Id) from Finnish b...</td>\n",
       "      <td>29044041</td>\n",
       "      <td>[{'lname': None, 'fname': None, 'affl': None}, {'lname': 'VennerstrÃ¶m', 'fname': 'Pia', 'affl': ...</td>\n",
       "      <td>Diseases of aquatic organisms</td>\n",
       "      <td>[]</td>\n",
       "      <td>10.3354/dao03161</td>\n",
       "      <td>None</td>\n",
       "      <td>10/18/2017</td>\n",
       "      <td>{'month': '10', 'year': '2017', 'day': '18'}</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Viral haemorrhagic septicaemia virus (VHSV Id) infections are detected more consistently using s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'NlmCategory': 'OBJECTIVE', 'Label': 'OBJECTIVE', 'text': 'To investigate the public health do...</td>\n",
       "      <td>29026457</td>\n",
       "      <td>[{'lname': None, 'fname': None, 'affl': None}, {'lname': 'Bhattarai', 'fname': 'Arjun Kumar', 'a...</td>\n",
       "      <td>Online journal of public health informatics</td>\n",
       "      <td>[]</td>\n",
       "      <td>10.5210/ojphi.v9i2.7985</td>\n",
       "      <td>None</td>\n",
       "      <td>10/13/2017</td>\n",
       "      <td>{'month': '10', 'year': '2017', 'day': '13'}</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Applications of information and communications technologies to public health: A scoping review u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'wholetext': 'Objective The objective was to forecast and validate prediction estimates of inf...</td>\n",
       "      <td>29026453</td>\n",
       "      <td>[{'lname': None, 'fname': None, 'affl': None}, {'lname': 'Paul', 'fname': 'Susannah', 'affl': 'R...</td>\n",
       "      <td>Online journal of public health informatics</td>\n",
       "      <td>[]</td>\n",
       "      <td>10.5210/ojphi.v9i2.8004</td>\n",
       "      <td>None</td>\n",
       "      <td>10/13/2017</td>\n",
       "      <td>{'month': '10', 'year': '2017', 'day': '13'}</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Modeling and Forecasting Influenza-like Illness (ILI) in Houston, Texas Using Three Surveillance...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              abstract  \\\n",
       "0                                                                                                 None   \n",
       "1  [{'wholetext': 'During winter 2014-15, England experienced severe strains on acute health servic...   \n",
       "2  [{'wholetext': 'The eradication of viral haemorrhagic septicaemia virus (VHSV Id) from Finnish b...   \n",
       "3  [{'NlmCategory': 'OBJECTIVE', 'Label': 'OBJECTIVE', 'text': 'To investigate the public health do...   \n",
       "4  [{'wholetext': 'Objective The objective was to forecast and validate prediction estimates of inf...   \n",
       "\n",
       "  associatedId  \\\n",
       "0     29057228   \n",
       "1     29048277   \n",
       "2     29044041   \n",
       "3     29026457   \n",
       "4     29026453   \n",
       "\n",
       "                                                                                                author  \\\n",
       "0  [{'lname': None, 'fname': None, 'affl': None}, {'lname': 'Barrett', 'fname': 'Damien', 'affl': '...   \n",
       "1  [{'lname': None, 'fname': None, 'affl': None}, {'lname': 'Smith', 'fname': 'Sue', 'affl': None},...   \n",
       "2  [{'lname': None, 'fname': None, 'affl': None}, {'lname': 'VennerstrÃ¶m', 'fname': 'Pia', 'affl': ...   \n",
       "3  [{'lname': None, 'fname': None, 'affl': None}, {'lname': 'Bhattarai', 'fname': 'Arjun Kumar', 'a...   \n",
       "4  [{'lname': None, 'fname': None, 'affl': None}, {'lname': 'Paul', 'fname': 'Susannah', 'affl': 'R...   \n",
       "\n",
       "                                       journal meshterms  \\\n",
       "0              Frontiers in veterinary science        []   \n",
       "1                 Emerging infectious diseases        []   \n",
       "2                Diseases of aquatic organisms        []   \n",
       "3  Online journal of public health informatics        []   \n",
       "4  Online journal of public health informatics        []   \n",
       "\n",
       "               optionalId01 optionalId02 publishdate  \\\n",
       "0  10.3389/fvets.2017.00150         None  10/23/2017   \n",
       "1    10.3201/eid2311.161632         None  10/19/2017   \n",
       "2          10.3354/dao03161         None  10/18/2017   \n",
       "3   10.5210/ojphi.v9i2.7985         None  10/13/2017   \n",
       "4   10.5210/ojphi.v9i2.8004         None  10/13/2017   \n",
       "\n",
       "                                publishdatefull          pubtype  \\\n",
       "0  {'month': '10', 'year': '2017', 'day': '23'}  Journal Article   \n",
       "1  {'month': '10', 'year': '2017', 'day': '19'}  Journal Article   \n",
       "2  {'month': '10', 'year': '2017', 'day': '18'}  Journal Article   \n",
       "3  {'month': '10', 'year': '2017', 'day': '13'}  Journal Article   \n",
       "4  {'month': '10', 'year': '2017', 'day': '13'}  Journal Article   \n",
       "\n",
       "                                                                                                 title  \n",
       "0                                The Potential for Big Data in Animal Disease Surveillance in Ireland.  \n",
       "1  Retrospective Observational Study of Atypical Winter Respiratory Illness Season Using Real-Time ...  \n",
       "2  Viral haemorrhagic septicaemia virus (VHSV Id) infections are detected more consistently using s...  \n",
       "3  Applications of information and communications technologies to public health: A scoping review u...  \n",
       "4  Modeling and Forecasting Influenza-like Illness (ILI) in Houston, Texas Using Three Surveillance...  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFull.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create classes for pushing data to access database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbName = access database name\n",
    "class NCBIPush:\n",
    "    def __init__(self, dbName):\n",
    "        self.dbName = dbName\n",
    "        \n",
    "        #function for connecting to database\n",
    "    def dbConnect(self):\n",
    "        #Connect to access database\n",
    "#        dbString = \"J:/ssUseCases/Database3.accdb\"\n",
    "        connStr = 'DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=%s;' % self.dbName\n",
    "        cnxn = pyodbc.connect(connStr)\n",
    "        cur = cnxn.cursor()\n",
    "        return(cnxn, cur)\n",
    "        \n",
    "    #Determining Pull Id\n",
    "    def pullId (self,cnxn):\n",
    "        query = \"select max(PullID) from DataPull_ID\"\n",
    "        pullIdDf = pd.read_sql_query(query,cnxn)\n",
    "        pullIdDf.columns = ['maxPullId']\n",
    "        idVal = pullIdDf['maxPullId'].isnull()\n",
    "        if idVal.bool():\n",
    "            pullVal = 1\n",
    "        else:\n",
    "            pullIdSeries = pullIdDf['maxPullId'] + 1\n",
    "            pullVal = pullIdSeries.iloc[0]\n",
    "        return(pullVal)\n",
    "    \n",
    "    #DataPull_ID table\n",
    "    def DataPull_ID(self,pullVal,cnxn,cur):\n",
    "        try:\n",
    "            pullId = pullVal.item()\n",
    "        except:\n",
    "            pullId = pullVal\n",
    "#         pullDate = date.today().strftime('%m/%d/%Y')\n",
    "        pullDate = datetime.datetime.now().strftime('%m/%d/%Y %I:%M:%S %p')\n",
    "        pullName = 'ss use cases'\n",
    "        pullQuery = pmSearchTerm\n",
    "        pullType = 'keyword' #keyword/ author\n",
    "        pullSource = db.upper()\n",
    "        pullBy = 'Sophie'\n",
    "\n",
    "        query = \"\"\" insert into DataPull_ID (PullID,PullDate,PullName,PullQuery,PullType,PullSource,PullBy) \n",
    "                    values (?,?,?,?,?,?,?) \"\"\"\n",
    "\n",
    "        args = (pullId,pullDate,pullName,pullQuery,pullType,pullSource,pullBy)\n",
    "\n",
    "        cur.execute(query, args)\n",
    "        #must commit in order to see it on sql server, if not sql server database won't load correctly\n",
    "        cnxn.commit()\n",
    "    \n",
    "    #DataPull_Detail table\n",
    "    def DataPull_Detail(self,cnxn,cur,dfFull):\n",
    "        accessPK = cur.execute(\"select @@IDENTITY\").fetchall()[0][0].__str__()\n",
    "        pullId = cur.execute(\"select distinct PullID from DataPull_ID where ID = ?\", (accessPK)).fetchall()[0][0].__str__()\n",
    "\n",
    "        #         #get all AssociatedIDs already in the database from same source\n",
    "        aidList = cur.execute(\"\"\"select distinct b.AssociatedID from DataPull_ID as a inner join DataPull_Detail as b on a.PullID = b.PullID where a.PullSource = ?\"\"\",db).fetchall()\n",
    "        existing_ids = {associatedid[0] for associatedid in aidList}\n",
    "\n",
    "\n",
    "        query = \"\"\" insert into DataPull_Detail ([PullID],[AssociatedID],[ValueStore],[PubType],[Note]) \n",
    "                            values (?,?,?,?,?) \"\"\"\n",
    "\n",
    "        note = None\n",
    "\n",
    "        values_list = []\n",
    "\n",
    "        #         #check how many associatedIDs there are\n",
    "        for index,row in dfFull.iterrows():\n",
    "\n",
    "            associatedidInt = int(row['associatedId'])\n",
    "            associatedid = str(associatedidInt)\n",
    "            pubtype = row['pubtype']\n",
    "            #check if associatedid is already in the database\n",
    "            if associatedid in existing_ids:\n",
    "                valuestore = 'duplicate'\n",
    "                #drop the row that already exists\n",
    "                dfFull.drop(index, inplace=True)\n",
    "            else:\n",
    "                valuestore = 'store'\n",
    "\n",
    "            values_list.append((pullId,associatedid,valuestore,pubtype,note))\n",
    "\n",
    "        if values_list!=[]:\n",
    "            cur.executemany(query, values_list)\n",
    "            cnxn.commit()\n",
    "\n",
    "    def DataPull_Title(self,cnxn,cur,dfFull):\n",
    "        query = \"\"\" insert into DataPull_Title (AssociatedID, Title, Journal, PublicationDate, pubDay,pubMonth,pubYear, OptionalID01,OptionalID02) values (?,?,?,?,?,?,?,?,?) \"\"\"\n",
    "\n",
    "        values_list = []\n",
    "\n",
    "        for index,row in dfFull.iterrows():\n",
    "            associatedid = int(row['associatedId'])\n",
    "            title = row['title']\n",
    "            journal = row['journal']\n",
    "            pubdate = row['publishdate']\n",
    "            doi = row['optionalId01']\n",
    "            pmid = row['optionalId02']    \n",
    "            if row['publishdatefull'] is not None:\n",
    "                dictDate = row['publishdatefull']\n",
    "                pubDay = dictDate['day']\n",
    "                pubMonth = dictDate['month']\n",
    "                pubYear = dictDate['year']\n",
    "\n",
    "            values_list.append((associatedid, title, journal ,pubdate,pubDay,pubMonth,pubYear, doi,pmid))\n",
    "\n",
    "\n",
    "        if values_list!=[]:\n",
    "            cur.executemany(query, values_list)\n",
    "            cnxn.commit()\n",
    "\n",
    "            \n",
    "            \n",
    "    def DataPull_Keyword(self,cnxn,cur,dfFull):\n",
    "        query = \"\"\" insert into DataPull_Keyword (AssociatedID, KeywordValue, Category1, Category2,\n",
    "                    Category3, Category4, Category5) values (?,?,?,?,?,?,?)\"\"\"\n",
    "        values_list = []\n",
    "\n",
    "        for index,row in dfFull.iterrows():\n",
    "            associatedid = int(row['associatedId'])\n",
    "\n",
    "            if row['meshterms'] is not None:\n",
    "\n",
    "                #each meshterm comes in as a dictionary (keys: qualifiernames & term)\n",
    "                #qualifiernames value = a list of qualifernames\n",
    "                #term value = the actual mesh term\n",
    "                for word in row['meshterms']:\n",
    "                    keywordvalue = word['term']\n",
    "\n",
    "                    try:\n",
    "                        num_of_qualifiers = len(word['qualifiernames'])\n",
    "                    except:\n",
    "                        num_of_qualifiers = 0\n",
    "\n",
    "                    #some have more than 5 qualifier names, if that is the case, then make num_of_Nones to 0 \n",
    "                    #needed to fill up ? marks with NULLS\n",
    "\n",
    "                    if num_of_qualifiers > 5:\n",
    "                        num_of_Nones = 0\n",
    "                        word['qualifiernames'] = word['qualifiernames'][:5]\n",
    "                    else:\n",
    "                        num_of_Nones = 5 - num_of_qualifiers\n",
    "\n",
    "                    #if there are qualifier names, the list should not be 0\n",
    "\n",
    "                    if num_of_qualifiers != 0:\n",
    "                        values_list.append(([associatedid,keywordvalue] + word['qualifiernames'] + [None]*num_of_Nones)) \n",
    "                    else:\n",
    "                        values_list.append((associatedid, keywordvalue, None, None, None, None, None))\n",
    " \n",
    "        if values_list!=[]:\n",
    "            cur.executemany(query, values_list)\n",
    "            cnxn.commit()\n",
    "        \n",
    "    def DataPull_Authors(self,cnxn,cur,dfFull):\n",
    "        #DataPull_Authors table\n",
    "        query = \"\"\" insert into DataPull_Author (AssociatedID, ForeName, LastName, Affiliation) values (?,?,?,?) \"\"\"\n",
    "\n",
    "        values_list = []\n",
    "\n",
    "        for index,row in dfFull.iterrows():\n",
    "            associatedid = int(row['associatedId'])\n",
    "            auth_count = 0\n",
    "\n",
    "            if row['author'] is not None:\n",
    "                for auth in row['author']:\n",
    "                    auth_count += 1\n",
    "                    if auth_count < 4:\n",
    "                        values_list.append((associatedid, auth['fname'], auth['lname'], auth['affl']))\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "        if values_list!=[]:\n",
    "            cur.executemany(query, values_list)\n",
    "            cnxn.commit()\n",
    "        \n",
    "        \n",
    "    def DataPull_Text(self,cnxn,cur,dfFull):        \n",
    "        \n",
    "        query = \"\"\" insert into DataPull_Text (associatedid, nlmcategory, label, abstracttext) values (?,?,?,?)\"\"\"\n",
    "\n",
    "        values_list = []\n",
    "\n",
    "        for index,row in dfFull.iterrows():\n",
    "            associatedid = int(row['associatedId'])\n",
    "\n",
    "            if row['abstract'] is not None:\n",
    "                for part in row['abstract']:\n",
    "\n",
    "                    #check if the abstract is just one chunk\n",
    "                    try:\n",
    "                        values_list.append((associatedid, None, None, part['wholetext']))\n",
    "                    except:\n",
    "                        values_list.append((associatedid, part['NlmCategory'], part['Label'], part['text']))\n",
    "\n",
    "        if values_list!=[]:\n",
    "            cur.executemany(query, values_list)\n",
    "            cnxn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dbString - should be the access database location\n",
    "dbString = \"J:/ssUseCases/Database6.accdb\"\n",
    "inst= NCBIPush(dbString)\n",
    "cn = inst.dbConnect()\n",
    "cnxn = cn[0]\n",
    "cur = cn[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = inst.pullId(cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to run all push methods of NCBIPush instance.\n",
    "def pushData(objInst,cnxn,cur,df):\n",
    "    #Generate new primary key \n",
    "    val = objInst.pullId(cnxn)\n",
    "    \n",
    "    #Push data into access database\n",
    "    objInst.DataPull_ID(val,cnxn,cur)\n",
    "    objInst.DataPull_Detail(cnxn,cur,df)\n",
    "    objInst.DataPull_Title(cnxn,cur,df)\n",
    "    objInst.DataPull_Keyword(cnxn,cur,df)\n",
    "    objInst.DataPull_Authors(cnxn,cur,df)\n",
    "    objInst.DataPull_Text(cnxn,cur,df)\n",
    "    return(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pushData(inst,cnxn,cur,dfFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
