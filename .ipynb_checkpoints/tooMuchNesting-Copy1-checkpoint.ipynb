{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import types\n",
    "import lxml.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc =  open('myxmlfile.xml').read()\n",
    "xml = lxml.html.fromstring(doc)\n",
    "article = xml.xpath(\"//pubmedarticle\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harmful Algal Bloom-Associated Illnesses in Humans and Dogs Identified Through a Pilot Surveillance System - New York, 2015.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Title\n",
    "article.xpath('//articletitle')[0].text_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDS\n",
    "idList = [elem.attrib for elem in article.xpath('//articleidlist/articleid[@idtype]')]\n",
    "idDictList = []\n",
    "for i in idList:\n",
    "    for k,v in i.items():\n",
    "        newPath = '//articleidlist/articleid[@idtype = \"' + v + '\"]'\n",
    "        valsList = article.xpath(newPath)\n",
    "        for val in valsList:\n",
    "            idDict = {}\n",
    "            idDict[v] = val.text_content()\n",
    "            idDictList.append(idDict)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'descriptorname': ['Adolescent']},\n",
       " {'descriptorname': ['Adult']},\n",
       " {'descriptorname': ['Animals']},\n",
       " {'descriptorname': ['Child']},\n",
       " {'descriptorname': ['Child, Preschool']},\n",
       " {'descriptorname': ['Disease'], 'qualifiername': ['etiology']},\n",
       " {'descriptorname': ['Dog Diseases'],\n",
       "  'qualifiername': ['epidemiology', 'etiology']},\n",
       " {'descriptorname': ['Dogs']},\n",
       " {'descriptorname': ['Female']},\n",
       " {'descriptorname': ['Harmful Algal Bloom']},\n",
       " {'descriptorname': ['Humans']},\n",
       " {'descriptorname': ['Male']},\n",
       " {'descriptorname': ['Middle Aged']},\n",
       " {'descriptorname': ['New York'], 'qualifiername': ['epidemiology']},\n",
       " {'descriptorname': ['Pilot Projects']},\n",
       " {'descriptorname': ['Population Surveillance']},\n",
       " {'descriptorname': ['Young Adult']}]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mesh terms\n",
    "meshList = [elem.tag for elem in article.xpath('//meshheadinglist/*')]\n",
    "msList = []\n",
    "for m in range(len(mesh_list)):\n",
    "    newDict = {}    \n",
    "    newDict[m] =  \"meshheading\"\n",
    "    msList.append(newDict)\n",
    "    msQList = article.xpath('//meshheadinglist/meshheading')  \n",
    "\n",
    "newerList = []\n",
    "newList = [elem.iterchildren() for elem in msQList]\n",
    "for n,nt in enumerate(newList):\n",
    "    b = [elem for elem in nt]   \n",
    "    tag_names = [elem.tag for elem in b]\n",
    "    unique_tag_names = list(set(tag_names))\n",
    "    newDict = {tag:[] for tag in unique_tag_names}\n",
    "#     newDict = {'descriptorname':[],'qualifiername':[]}\n",
    "    for elem in b:\n",
    "        newDict[elem.tag].append(elem.text_content())\n",
    "    newerList.append(newDict)\n",
    "newerList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            d = {\n",
    "                        'title': title,\n",
    "                        'associatedId' : associatedId,\n",
    "                        'author': authList,    \n",
    "                        'journal' : journal,\n",
    "                        'pubtype': pubTypeVal,\n",
    "                        'publishdate': dateVal,\n",
    "                        'publishdatefull': dateDictVal,\n",
    "                        'meshterms': meshList,\n",
    "                        'abstract': abstractList,\n",
    "                        'optionalId01' : doi,\n",
    "                        'optionalId02': pmid\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  ArticleList = soup.find_all('PubmedArticle')\n",
    "            articleList = []\n",
    "\n",
    "            for article in ArticleList:\n",
    "                ssList = []\n",
    "\n",
    "                 ####### title ########\n",
    "                title = article.find('ArticleTitle').text\n",
    "\n",
    "                ####### pmid #########\n",
    "                associatedId = article.find('PMID').text\n",
    "\n",
    "                ####### journal ########\n",
    "                journal = article.find('Title').text   \n",
    "\n",
    "                ####### meshterms ##########\n",
    "\n",
    "                #each meshterm will have its word and possibly some qualifiernames\n",
    "                meshList = []\n",
    "\n",
    "                try:\n",
    "                    meshTermList = article.find_all('MeshHeading')\n",
    "                    for term in meshTermList:\n",
    "                        descriptorTerm = term.find('DescriptorName').text\n",
    "                        qualifierList = []\n",
    "                        try:\n",
    "                            qualifierNameList = term.find_all('QualifierName')\n",
    "                            for qual in qualifierNameList:\n",
    "                                thisQual = qual.text\n",
    "                                qualifierList.append(thisQual)\n",
    "                        except: \n",
    "                            qualifierList = None\n",
    "\n",
    "                        mtDict = {'term': descriptorTerm, 'qualList': qualifierList}\n",
    "                        meshList.append(mtDict)\n",
    "                except:\n",
    "                    meshList = None\n",
    "\n",
    "                ######## article date ###########\n",
    "\n",
    "                if article.find('ArticleDate'):\n",
    "                    year = article.find('DateCreated').find('Year').text\n",
    "                    month = article.find('DateCreated').find('Month').text\n",
    "                    day = article.find('DateCreated').find('Day').text\n",
    "                    dateDict = {'month':month,'year':year,'day':day}\n",
    "                    fulldate = '{0}/{1}/{2}'.format(month,day,year)\n",
    "                if not article.find('ArticleDate'):\n",
    "                    year = article.find('DateCreated').find('Year').text\n",
    "                    month = article.find('DateCreated').find('Month').text\n",
    "                    day = article.find('DateCreated').find('Day').text\n",
    "                    dateDict = {'month':month,'year':year,'day':day}\n",
    "                    fulldate = '{0}/{1}/{2}'.format(month,day,year)\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "                ######### pubtype ##########\n",
    "#                 pubTypeVal = \"\"\n",
    "#                 try:\n",
    "#                     pubTypes = article.find_all('PublicationType')\n",
    "#                     for pub in pubTypes:\n",
    "#                         try:\n",
    "#                             pubTypeVal = pub.text\n",
    "#                         except:\n",
    "#                             pubTypeVal = None   \n",
    "#                 except:\n",
    "#                     pubTypeVal = None\n",
    "\n",
    "                pubTypeVal = \"\"\n",
    "                try:\n",
    "                    pubTypes = article.find('PublicationType')\n",
    "                    pubTypeVal = pubTypes.text\n",
    "                except:\n",
    "                    pubTypeVal = None\n",
    "                    \n",
    "                    \n",
    "                ######### abstract ##########\n",
    "\n",
    "                abstractList = []\n",
    "                try:\n",
    "                    abstractText = article.find('Abstract')\n",
    "                    sections = abstractText.find_all('AbstractText')\n",
    "                    if sections[0].get('Label'):\n",
    "                        #broken up by nlm category\n",
    "                        for sec in sections:\n",
    "                            abstractDict = {}\n",
    "                            abstractDict['NlmCategory'] = sec.get('NlmCategory')\n",
    "                            abstractDict['Label'] = sec.get('Label')\n",
    "                            abstractDict['text'] = sec.text\n",
    "                            abstractList.append(abstractDict)\n",
    "                    if not sections[0].get('Label'):\n",
    "                        #comes as whole chunk\n",
    "                        abstractDict = {}\n",
    "                        abstractFull = abstractText.find('AbstractText').text\n",
    "                        abstractDict['wholetext'] = abstractFull\n",
    "                        abstractList.append(abstractDict)\n",
    "                except:\n",
    "                    #this means there is no abstract at all\n",
    "                    abstractList = None\n",
    "\n",
    "                ############ authors ###############\n",
    "\n",
    "                #each article will have a list of authors. Each author is represented by a dictionary (key values: fname, lname, affliation)\n",
    "                authList = []\n",
    "                #some articles don't have an author\n",
    "                try:          \n",
    "                    authorList = article.find('AuthorList')\n",
    "                    for author in authorList:\n",
    "                        try:\n",
    "                            affiliation = author.find('CollectiveName').text\n",
    "                            lname = None\n",
    "                            fname = None\n",
    "                        except:\n",
    "                            try:\n",
    "                                lname = author.find('LastName').text\n",
    "                            except:\n",
    "                                lname = None\n",
    "                            try:\n",
    "                                fname = author.find('ForeName').text\n",
    "                            except:\n",
    "                                fname = None\n",
    "                            try:\n",
    "                                affiliation = author.find('Affiliation').text\n",
    "                            except:\n",
    "                                affiliation = None\n",
    "                            authDict = {'lname':lname,'fname':fname, 'affl':affiliation}\n",
    "                            authList.append(authDict)\n",
    "\n",
    "                except:\n",
    "                    authList = None\n",
    "\n",
    "                ######### doi ##########\n",
    "                doi = None\n",
    "\n",
    "                try:\n",
    "                    doiList = article.find_all('ArticleId')\n",
    "\n",
    "                    for doiM in doiList:\n",
    "                        if doiM.get('IdType') == 'doi':\n",
    "                            doi = doiM.text\n",
    "                except:\n",
    "\n",
    "                    try:\n",
    "                        doiList = article.find_all('ELocationID')\n",
    "                        for doiM in doiList:\n",
    "                            if doiM.get('IdType') == 'doi':\n",
    "                                doi = doiM.text\n",
    "                    except:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
